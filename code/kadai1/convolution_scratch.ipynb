{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【第一回目　課題２】フレームワークを使わない深層学習 (2): 畳み込み編\n",
    "\n",
    "次は，フレームワークを使わないで畳み込み層を実装してみます．順伝搬でim2col, 逆伝搬でcol2imを使えば，基本は全結合と同じである，という点がポイントです．im2col, col2imを使わずに実装するのはかなり複雑で，単純に実装すると6重ループになりますので，通常のフレームワークではim2col, col2imで計算するのが一般的です．\n",
    "\n",
    "順伝搬は，im2col によって，feature mapをim2col表現に展開します．そうすると，畳み込みは フィルタ行列とim2col行列の行列積として表現できます．\n",
    "つまり，im2col + 全結合層　と等価になります．\n",
    "\n",
    "逆伝搬は，逆をたどれば良いので，全結合の逆伝搬 + im2col表現のfeature mapへの逆変換 (col2im変換)となります．\n",
    "\n",
    "まとめると，im2col, col2imの変換ができれば，あとは全結合の順伝搬計算，逆伝搬計算がそのまま利用できます．\n",
    "\n",
    "では，im2col, col2im を実装してみましょう．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さあ，Convクラスを実装します．課題1のFCクラスを継承してもいいですが，コードを再利用して，独立に実装してみます．\n",
    "__call__(), backfard() に加えて，im2col, col2im関数を追加します．\n",
    "\n",
    "順伝搬は，最初にim2colの呼び出し，次にFcと同じ行列の積和演算，最後に追加で，\n",
    "(n_filter,out_h$\\times$out_w) のサイズの出力を (n_filter,out_h,out_w) にreshapeして，3次元のfeature mapに変形して出力します．\n",
    "\n",
    "逆伝搬は，最初に(n_filter,out_h,out_w)のfeature mapに関する勾配を　(n_filter,out_h$\\times$out_w) の行列に変換して，\n",
    "Fcの時と同じ逆伝搬計算を行います．最後に，dEdyに関して，col2im変換を行って，3次元のfeature mapに変形して出力します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv:\n",
    "    def __init__(self,c,h,w,n_filter,pad=0,stride=1,relu=True, seed=0):\n",
    "        self.filter = (c,w,h)\n",
    "        self.filter_c = c; self.filter_h=h; self.filter_w=w\n",
    "        self.n_filter = n_filter\n",
    "        self.pad = pad\n",
    "        self.stride = stride\n",
    "        self.relu= relu\n",
    "        n_in = c * w * h\n",
    "        self.n_in = n_in\n",
    "        n_out = n_filter\n",
    "        # 学習パラメータは, 重み行列w(=フィルタ), バイアス項b\n",
    "        # サイズは以下の通り\n",
    "        self.size_w = (n_out,n_in)\n",
    "        self.size_b = (n_out,1)\n",
    "        # w,b は全結合層の学習パラメータ．\n",
    "        # ReLuも全結合の中にいれてある．\n",
    "        # ReLU=Trueのときは，Heの初期値．Falseのときは，Xavierの初期値とする．\n",
    "        # xは直前のforward計算時の入力値．BPの計算時に必要． \n",
    "        np.random.seed(seed) # 同じ初期値を再現できるように seed を指定します．\n",
    "        if relu:\n",
    "            self.w = np.random.normal(0, math.sqrt(2.0/n_in), self.size_w) # Heの初期値\n",
    "            self.relu0 = None # ReLUの順伝搬時に０以下で値が伝搬されない要素のインデックスを記録．BP時に利用．\n",
    "        else:\n",
    "            self.w = np.random.normal(0, math.sqrt(1.0/n_in), self.size_w) # Xavierの初期値   \n",
    "        self.b = np.zeros((n_out,1))\n",
    "        self.x = np.zeros((n_in,1))\n",
    "        # 誤差逆伝搬(Back-Propagation時の勾配を記録する変数)\n",
    "        self.dEdx = np.zeros((n_in,1)) # dE/dx を表す　BPの時に直前レイヤに伝わる勾配でδと表現されます．\n",
    "        self.dEdw = np.zeros((n_out,n_in)) # dE/dw を表す\n",
    "        self.dEdb = np.zeros((n_out,1)) # dE/db を表す\n",
    "        self.count = 0\n",
    "        # 以下，MomentamSDGのための設定\n",
    "        self.mdw = np.zeros((n_out,n_in))\n",
    "        self.mdb = np.zeros((n_out,1))\n",
    "    \n",
    "    # forward は __call__ を使って定義する．im2col + 行列積和．\n",
    "    def __call__(self,input_):   # 入力はfeature map\n",
    "        x,out_h,out_w = self.im2col(input_) # x のサイズは (self.n_in, out_h*out_w)\n",
    "        self.x = x\n",
    "        #self.size_input=input.shape\n",
    "        #self.size_output=(self.n_filter,out_h,out_w)\n",
    "        self.out_h = out_h\n",
    "        self.out_w = out_w\n",
    "        # w のサイズは，(n_filter, n_in), よって y のサイズは (n_filter,out_h*out_w)\n",
    "        self.y = np.dot(self.w, x) + self.b\n",
    "        # ReLUは，値が０以下の要素は，０とする．０とした要素のインデックスは relu0に記録し，BP時に勾配を伝搬させない．\n",
    "        if self.relu:\n",
    "            self.relu0= self.y<=0\n",
    "            self.y[self.relu0] = 0\n",
    "        # 最後に，(n_filter,out_h,out_w) にreshape\n",
    "        return np.reshape(self.y,(self.n_filter,out_h,out_w))\n",
    "\n",
    "    # backward は，dE/dy を受け取って，dE/dx を出力．内部では，dE/dw, dE/db を更新\n",
    "    def backward(self, dEdy0):\n",
    "        dEdy = np.reshape(dEdy0,(self.n_filter,self.out_h*self.out_w))\n",
    "        # 順伝搬時に値が０以下だった要素は勾配を０として，勾配伝搬しない．\n",
    "        if self.relu:\n",
    "            dEdy[self.relu0] = 0\n",
    "        dydx = np.transpose(self.w)  # dWx/dx= np.transpose(W) であることより．\n",
    "        dydw = np.transpose(self.x)  # dWx/dW= np.transpose(x) \n",
    "        # dydb = np.ones((self.n_out,1))   #  db/db = np.ones((n_out,1))　１なので特に計算しない．\n",
    "        # dEdw, dEdb に勾配を加算．dEdx (δ)は前層へ伝搬する勾配で，backwardの返り値とする．\n",
    "        self.dEdx = np.dot(dydx, dEdy)\n",
    "        self.dEdw += np.dot(dEdy, dydw)\n",
    "        self.dEdb += np.c_[np.sum(dEdy, axis=1)]  # channelごとにfeature map 全体が1つのバイアスに対応するので channelごとにsumします．\n",
    "        # 勾配の平均を取るために，足した勾配のサンプル数を記録．\n",
    "        # conv の場合は，フィルタを適用した回数．つまり，出力feature mapの画素数\n",
    "        self.count += (self.out_h*self.out_w)  \n",
    "        # 最後に，col2imでfeature mapに対応するδを求める\n",
    "        out=self.col2im(self.dEdx)\n",
    "        return out\n",
    "\n",
    "    # im2col は，feature map を　縦が1回の畳み込みに必要な局所画像サイズ(filter_c*filter_h*filter_w)，\n",
    "    # 横が(out_h*out_w) になる行列に変換する関数 \n",
    "    def im2col(self,input_):\n",
    "        c, h, w = input_.shape\n",
    "        out_h = (h + 2*self.pad - self.filter_h)//self.stride + 1\n",
    "        out_w = (w + 2*self.pad - self.filter_w)//self.stride + 1\n",
    "        # padding 分をzero paddingで追加したimを生成\n",
    "        im = np.pad(input_, [(0,0), (self.pad, self.pad), (self.pad, self.pad)], 'constant')\n",
    "        # filterの各x,yの位置ごとに，対応するfeature mapの値を格納し，\n",
    "        # 最後に transpose -> reshape で，im2col出力行列を生成\n",
    "        col = np.zeros((c, self.filter_h, self.filter_w, out_h, out_w))\n",
    "    \n",
    "        for y in range(self.filter_h):\n",
    "            y_max = y + self.stride*out_h\n",
    "            for x in range(self.filter_w):\n",
    "                x_max = x + self.stride*out_w\n",
    "                # filterの位置に応じてずらしてfeature mapをコピー\n",
    "                # stride>1の時は飛ばしてfeature mapをコピー\n",
    "                col[:, y, x, :, :] = im[:, y:y_max:self.stride, x:x_max:self.stride]\n",
    "        # チャネル軸を1番目から3番目に移動して，reshapeして，(filter_c,out_h*out_w)とする\n",
    "        col = col.transpose(1, 2, 0, 3, 4).reshape((self.n_in, out_h*out_w))\n",
    "        return col,out_h,out_w\n",
    "\n",
    "    # col2im は，im2col形式の勾配δをfeature map形式に変換する．逆伝搬で使用．\n",
    "    def col2im(self,col):\n",
    "        col_h, col_w = col.shape # (filter_c*filter_h*filter_w, out_h*out_w)\n",
    "        h = (self.out_h-1)*self.stride + self.filter_h\n",
    "        w = (self.out_w-1)*self.stride + self.filter_w\n",
    "        c = self.filter_c\n",
    "    \n",
    "        # サイズ(x,h,w)の im 行列を0で初期化\n",
    "        im = np.zeros((c,h,w))\n",
    "        # feature map colの各場所について，勾配を対応するimの場所に加算する\n",
    "        for j in range(self.out_h):\n",
    "            for i in range(self.out_w):\n",
    "                im[:, j:j+self.filter_h, i:i+self.filter_w] += np.reshape(col[:, j * self.out_w + i],(c,self.filter_h,self.filter_w))\n",
    "        return im[:,self.pad:h-self.pad,self.pad:w-self.pad]        \n",
    "\n",
    "    # 以下は，updater で，Fcと同じ実装です．ちゃんと実装するなら，super classにする方がいいでしょう．\n",
    "    # 勾配をクリア\n",
    "    def clear_grad(self):\n",
    "        self.dEdw = 0\n",
    "        self.dEdb = 0\n",
    "        self.count = 0\n",
    "\n",
    "    # 勾配法で重みをアップデート．countで割って，足しこんだ勾配のサンプル数で平均を取る\n",
    "    def update(self, lr=0.001):\n",
    "        self.w -= self.dEdw/self.count * lr\n",
    "        self.b -= self.dEdb/self.count * lr\n",
    "        self.clear_grad()\n",
    "    \n",
    "    # 慣性項（モーメンタム項）付きの勾配法 課題1の5\n",
    "    def updatem(self, lr=0.001, mu=0.9):\n",
    "        self.mdw = mu * self.mdw - (self.dEdw/self.count) * lr\n",
    "        self.mdb = mu * self.mdb - (self.dEdb/self.count) * lr\n",
    "        self.w += self.mdw\n",
    "        self.b += self.mdb\n",
    "        self.clear_grad()\n",
    "    \n",
    "    # adagrad (課題2 任意発展課題の2)\n",
    "    def update_adagrad(self, lr=0.001):\n",
    "        self.h += (self.dEdw/self.count)**2\n",
    "        self.w -= lr * (self.dEdw/self.count)/(np.sqrt(self.h + 1e-7))\n",
    "        self.b -= lr * (self.dEdb/self.count)/(np.sqrt(self.h + 1e-7))\n",
    "        self.clear_grad()\n",
    "        \n",
    "    def update_adam(self, lr =0.001, beta1=0.9, beta2=0.99):\n",
    "        self.mw = beta1 * self.m - (1 - beta1) * (self.dEdw/self.count)\n",
    "        self.vw = beta2 * self.v - (1 - beta2) * (self.dEdw/self.count)**2\n",
    "        \n",
    "        self.mb = beta1 * self.m - (1 - beta1) * (self.dEdb/self.count)\n",
    "        self.vb = beta2 * self.v - (1 - beta2) * (self.dEdb/self.count)**2\n",
    "        \n",
    "        mhat_w = self.mw / (1 - beta1**count)\n",
    "        vhat_w = self.vw / (1 - beta2**count)\n",
    "        \n",
    "        mhat_b = self.mb / (1 - beta1**count)\n",
    "        vhat_b = self.vb / (1 - beta2**count)\n",
    "        \n",
    "        self.w -= lr * mhat_w/(np.sqrt(vhat_w) + 1e-7)\n",
    "        self.b -= lr * mhat_b/(np.sqrt(vhat_b) + 1e-7)\n",
    "        \n",
    "        self.clear_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では，ここでは，簡単な問題として，グレーススケール化とエッジ検出のフィルタを3層の畳み込みネットワークで学習してみましょう．\n",
    "\n",
    "とりあえず，画像1枚だけで学習します．畳み込みはフィルタをスライドさせて演算しますので，スライドさせる分だけ別々のデータで学習を行っているのと等価になります．例えば，3x3のフィルタを320x240の画像で学習すれば，320x240通りでスライドできますので，Fc層での学習を76800回行ったのと等価になります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature,filters\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_matrix(img_path, method=\"canny\"):\n",
    "    \"\"\"\n",
    "    入力画像を配列化しエッジを抽出した画像を配列化\n",
    "    グレースケール化した画像を配列化する関数\n",
    "    \n",
    "    入力\n",
    "    img_path(str): 画像のファイルパス\n",
    "    method: エッジ抽出の方法 cannyかsobelを想定\n",
    "    \n",
    "    出力\n",
    "    img: 配列化した画像\n",
    "    edge: エッジ抽出した画像\n",
    "    grey: グレースケール化した画像\n",
    "    \"\"\"\n",
    "    img_org = Image.open(img_path).resize((320,240))\n",
    "    img = np.array(img_org, dtype=np.uint8)\n",
    "    gray = np.array(img_org.convert('L'), dtype=np.uint8)\n",
    "    if method == \"canny\":\n",
    "        edge = feature.canny(gray,sigma=2)  # Canny でエッジ抽出\n",
    "        edge = edge * 255\n",
    "        return img, edge, gray\n",
    "    elif method == \"sobel\":\n",
    "        edge = filters.sobel(gray) # Sobel でエッジ抽出\n",
    "        edge = edge * 255\n",
    "        return img, edge, gray\n",
    "    else:\n",
    "        raise ValueError(\"Invalid edge extraction method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, edge, gray = convert_image_to_matrix(\"../figure/uec.jpg\", \"sobel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "読み込んだ画像と変換した画像を，numpy形式に変換します．\n",
    "(c,h,w) c:チャネル, h:高さ, w:幅　のサイズの3次元配列にします．\n",
    "ここでは画像は320x240で，入力はカラーなので，\n",
    "input: (3,240,320)\n",
    "output: (1,240,320)\n",
    "の大きさです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エッジ検出フィルタ，グレースケール化フィルタの切り替え\n",
    "def convert_pixel_value(img, edge, gray, use_edge=True):\n",
    "    \"\"\"\n",
    "    画像を行列に変換\n",
    "    入力 \n",
    "    img:入力画像\n",
    "    edge: エッジ抽出した画像\n",
    "    gray: グレースケール化した画像\n",
    "    use_edge(bool): エッジ化した画像を使うかどうか\n",
    "    \n",
    "    出力\n",
    "    [-1,1)の範囲に制限した入力画像と出力画像\n",
    "    \n",
    "    \"\"\"\n",
    "    if use_edge:\n",
    "        gt = edge\n",
    "    else:\n",
    "        gt = gray\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(122)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.imshow(gt,plt.cm.gray)\n",
    "\n",
    "    # 画素値が [-1,1) の範囲の値になるように変換\n",
    "    input_  = (np.asarray(img, dtype=np.float32).transpose(2,0,1)-128)/128.0\n",
    "    output = (np.expand_dims(np.asarray(gt, dtype=np.float32),0)-128)/128.0\n",
    "    return input_, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_, output = convert_pixel_value(img, edge, gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込み層を3つ用意します．\n",
    "3x3x10 -> 3x3x10 -> 3x3x1 です．\n",
    "1,2層目はReLU付きです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Conv(3,3,3,10,pad=1)\n",
    "c2 = Conv(10,3,3,10,pad=1)\n",
    "c3 = Conv(10,3,3,1,pad=1,relu=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習ループです．\n",
    "学習率lr = 0.01\n",
    "エポック数200とします．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_learning_result(input_, output, c1, c2, c3, lr=0.1, mu=0.9, beta1=0.9, beta2=0.99, num_epoch=200, optimizer=\"sgd\"):\n",
    "    \"\"\"\n",
    "    fc1: 畳み込み層の1層目\n",
    "    fc2: 畳み込み層の2層目\n",
    "    fc3:畳み込み層の3層目\n",
    "    learning_rate(float): 学習率\n",
    "    mu(float): 慣性項の係数 momentum_sgdで使用\n",
    "    beta1(float): adamで利用するパラメータ\n",
    "    beta2(float): adamで利用するパラメータ\n",
    "    num_epoch(int): エポック数\n",
    "    optimizer(list): 勾配の最適化方法 [\"sgd\", \"momentum_sgd\", \"adam\", \"adagrad\"]という文字列を代入することを想定\n",
    "    \"\"\"\n",
    "    lr = lr\n",
    "    num_epoch = num_epoch\n",
    "    losses = np.array([])\n",
    "    ep = np.array([])\n",
    "\n",
    "    # 表示エリアの設定\n",
    "    fig = plt.figure()\n",
    "    fig1 = fig.add_subplot(121)\n",
    "    fig2 = fig.add_subplot(122)\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        if epoch > 0 and epoch %100 ==0:\n",
    "            lr *= 0.1\n",
    "        # 順伝搬計算\n",
    "        y = c3(c2(c1(input_)))\n",
    "        # 誤差微分値，誤差値を計算します． \n",
    "        dEdx = y - output\n",
    "        loss = np.sum(dEdx**2)*0.5/(y.shape[1] * y.shape[2])\n",
    "        # print(\"epoch: {} loss: {} lr: {}\".format(epoch, loss,lr))\n",
    "        # dEdx (δ)を計算して，逆伝搬します．\n",
    "        dEdx = c3.backward(dEdx)\n",
    "        dEdx = c2.backward(dEdx)\n",
    "        dEdx = c1.backward(dEdx)\n",
    "        # 順伝搬，逆伝搬を行ったら，SDGで重みを更新\n",
    "        # out_h*out_w 分の順伝搬の勾配がすべて合計されていますので，\n",
    "        # batchsize 1 でも，実質batchisizeは out_h*out_w (例えば，320*240だと76800)になります．\n",
    "        if optimizer == \"sgd\":\n",
    "            c1.update(lr)\n",
    "            c2.update(lr)\n",
    "            c3.update(lr)\n",
    "        elif optimizer == \"momentum_sgd\":\n",
    "            c1.updatem(lr, mu)\n",
    "            c2.updatem(lr, mu)\n",
    "            c3.updatem(lr, mu)\n",
    "        elif optimizer == \"adam\":\n",
    "            c1.update_adam(lr, beta1, beta2)\n",
    "            c2.update_adam(lr, beta1, beta2)\n",
    "            c3.update_adam(lr, beta1, beta2)\n",
    "        elif optimizer == \"adagrad\":\n",
    "            c1.update_adagrad(lr)\n",
    "            c2.update_adagrad(lr)\n",
    "            c3.update_adagrad(lr)\n",
    "\n",
    "        losses = np.append(losses,loss)\n",
    "        ep = np.append(ep,epoch)\n",
    "        if epoch % 10 == 0:\n",
    "            display.clear_output(wait = True)\n",
    "            fig1.axis([0, num_epoch, 0, 0.5])\n",
    "            fig1.plot(ep,losses,\"r\")\n",
    "            out = (y.squeeze()+1.0)*128.0 # 表示するときは，[0.256)に戻します．\n",
    "            fig2.axis(\"off\")\n",
    "            fig2.imshow(out,cmap=\"gray\",vmin=0,vmax=255)\n",
    "            display.display(fig)\n",
    "            if epoch < num_epoch - 1:\n",
    "                fig2.cla()\n",
    "\n",
    "    display.clear_output(wait = True)\n",
    "    fig1.plot(ep,losses,\"r\")\n",
    "    fig2.imshow(out,cmap=\"gray\",vmin=0,vmax=255)\n",
    "    print(\"loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_learning_result(input_, output, c1, c2, c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 課題2\n",
    "以下の小問の(1)-(5)を解答せよ．\n",
    "\n",
    "1. 上記のコードにおける畳込み層の順伝搬，逆伝搬の計算方法を説明せよ．さらに，自分で用意した画像に対して，上記のコードを実行せよ．\n",
    "1. モデルパラメータ（例えば，10->20) を変化させて，結果を比較せよ．(特に最終loss値)\n",
    "1. 学習率を変化させて挙動を観察せよ．\n",
    "1. 1,2層にReLUを入れた場合と，3層ともReLUなしの場合の結果を比較せよ．\n",
    "1. モーメンタムSDGに変更して，ノーマルなSDGとの違いを観察せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【課題2: 任意発展課題】\n",
    "興味のある人は，例えば，以下のような拡張を行ってみよ．\n",
    "\n",
    "1. 複数枚の学習画像(2～10枚程度)に対応させて，lossの下がり方の違いについて観察せよ．random shuffleは入れても入れなくてもよい．\n",
    "1. Adam, AdaGrad のどちらか一方，もしくは両方を実装して比較せよ．\n",
    "1. 最終層の活性化関数に tanhを利用せよ．\n",
    "1. Batch Normalization Layerを追加せよ．\n",
    "1. Max pooling layerを実装せよ．Average Pooling も実装するとなお良い．\n",
    "1. 上記のmini-batch対応を行った後，cupy ライブラリを使って，GPUに対応させよ．\n",
    "1. SoftMax関数を追加し，Max Pooling, Fcクラスと組み合わせて，MNISTやCIFAR-10のサブセットなど，分類タスクを行ってみよ．(minibatch単位の計算+cupyの利用がないとおそらく厳しい．)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 課題2 1.上記のコードにおける畳込み層の順伝搬，逆伝搬の計算方法を説明せよ．さらに，自分で用意した画像に対して，上記のコードを実行せよ．\n",
    "順伝搬，逆伝搬の計算を説明．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自分で用意した画像で実行\n",
    "img_myimg, edge_myimg, gray_myimg = convert_image_to_matrix(\"../figure/lena.jpg\",\"sobel\")\n",
    "input_myimg, output_myimg =  convert_pixel_value(img_myimg, edge_myimg, gray_myimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Conv(3,3,3,10,pad=1)\n",
    "c2 = Conv(10,3,3,10,pad=1)\n",
    "c3 = Conv(10,3,3,1,pad=1,relu=0)\n",
    "show_learning_result(input_myimg, output_myimg, c1, c2, c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 課題2 2. モデルパラメータ（例えば，10->20) を変化させて，結果を比較せよ．(特に最終loss値)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_changed = Conv(3,3,3,10,pad=1)\n",
    "c2_changed = Conv(10,3,3,100,pad=1)\n",
    "c3_changed = Conv(100,3,3,1,pad=1,relu=0)\n",
    "\n",
    "show_learning_result(input_, output, c1_changed, c2_changed, c3_changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_changed = Conv(3,3,3,10,pad=1)\n",
    "c2_changed = Conv(10,3,3,5,pad=1)\n",
    "c3_changed = Conv(5,3,3,1,pad=1,relu=0)\n",
    "\n",
    "show_learning_result(input_ output, c1_changed, c2_changed, c3_changed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 課題2 3. 学習率を変化させて挙動を観察せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Conv(3,3,3,10,pad=1)\n",
    "c2 = Conv(10,3,3,10,pad=1)\n",
    "c3 = Conv(10,3,3,1,pad=1,relu=0)\n",
    "\n",
    "# デフォルトの値0.001よりも学習率を高くする\n",
    "show_learning_result(input_, output, c1, c2, c3, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Conv(3,3,3,10,pad=1)\n",
    "c2 = Conv(10,3,3,10,pad=1)\n",
    "c3 = Conv(10,3,3,1,pad=1,relu=0)\n",
    "\n",
    "# デフォルトの値0.001よりも学習率を高くする\n",
    "show_learning_result(input_, output, c1, c2, c3, lr=10**-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 課題2 4. 1,2層にReLUを入れた場合と，3層ともReLUなしの場合の結果を比較せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_without_relu = Conv(3,3,3,10,pad=1,relu=0)\n",
    "c2_without_relu = Conv(10,3,3,10,pad=1,relu=0)\n",
    "c3_without_relu = Conv(10,3,3,1,pad=1,relu=0)\n",
    "\n",
    "show_learning_result(input_, output, c1_without_relu, c2_without_relu, c3_without_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 課題2 5. モーメンタムSDGに変更して，ノーマルなSDGとの違いを観察せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Conv(3,3,3,10,pad=1)\n",
    "c2 = Conv(10,3,3,10,pad=1)\n",
    "c3 = Conv(10,3,3,1,pad=1,relu=0)\n",
    "\n",
    "show_learning_result(input_, output, c1, c2, c3, optimizer=\"momentum_sgd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
