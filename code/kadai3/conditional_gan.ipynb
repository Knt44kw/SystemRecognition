{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"conditional_gan.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4JgHZEwe8b-J"},"source":["* Conditional GAN (CGAN)"]},{"cell_type":"code","metadata":{"id":"UVSREV_B8geI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612581552880,"user_tz":-540,"elapsed":568,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}},"outputId":"89b3c2ea-1c08-4f15-b92c-d6627991e085"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Eb5oASSW8Ozn"},"source":["# カレントディレクトリの読み込みとカレントディレクトリへの移動\n","import sys\n","sys.path.append(f'/content/drive/My Drive/system/')\n","import os\n","os.chdir(f'/content/drive/My Drive/system/myanswer')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0DPESSkHo7DN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612581555356,"user_tz":-540,"elapsed":3031,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}},"outputId":"24051002-739e-4323-d89e-4adf0b0355bd"},"source":["!pip install scipy==1.1.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SsYl_BKb8O1k"},"source":["from __future__ import print_function, division\n","from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n","from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","from glob import glob\n","import pickle\n","import datetime\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import scipy\n","import scipy.misc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FJVdPKCV8T7p"},"source":["class DataLoader():\n","    def __init__(self, num_classes=10, img_res=(128, 128)):\n","        self.num_classes = num_classes\n","        self.img_res = img_res\n","\n","    def load_data(self, is_testing=False):\n","        if os.path.exists(\"../pickle/foodimg128_tensor_{}classes.pickle\".format(self.num_classes)) and os.path.exists(\"../pickle/foodimg128_label_{}classes.pickle\".format(self.num_classes)):\n","            with open('../pickle/foodimg128_tensor_{}classes.pickle'.format(self.num_classes), 'rb') as p:\n","                imgs = pickle.load(p)\n","            with open('../pickle/foodimg128_label_{}classes.pickle'.format(self.num_classes), 'rb') as p:\n","                labels = pickle.load(p)\n","        else:\n","            imgs = [] # テンソル化した 画像を格納するリスト\n","            labels = [] # 食べ物画像のラベルを格納するリスト\n","\n","            food_dict = {0: \"bibimba\", 1:\"chahan\", 2:\"chikenrice\", 3:\"curry\", 4:\"ebichill\", \n","                        5:\"gratin\", 6:\"gyudon\", 7:\"hiyachu\", 8:\"kaisendon\", 9:\"katsudon\", \n","                        10:\"meatspa\", 11:\"omelet\", 12:\"omurice\", 13:\"oyakodon\", \n","                        14:\"pilaf\", 15:\"pizza\", 16:\"ramen\", 17:\"rice\", 18:\"soba\",\n","                        19:\"steak\"}\n","\n","            for label, food_name in food_dict.items():\n","                img_pathes = glob('../figure/foodimg128/{}/*.jpg'.format(food_name))\n","                print(\"current food image {} labeled {}\".format(food_name, label))\n","                for img_path in img_pathes:\n","                    each_img = self.imread(img_path)\n","                    if not is_testing:\n","                        each_img = scipy.misc.imresize(each_img, self.img_res)\n","                        if np.random.random() > 0.5:\n","                            each_img = np.fliplr(each_img)\n","                    else:\n","                        each_img = scipy.misc.imresize(each_img, self.img_res)       \n","                    imgs.append(each_img)\n","                    labels.append(label)\n","                print(\"finished generating dataset {} labeled {}\".format(food_name, label))\n","            \n","            with open('../pickle/foodimg128_tensor_{}classes.pickle'.format(self.num_classes), 'wb') as p:\n","                pickle.dump(imgs , p)\n","            with open('../pickle/foodimg128_label_{}classes.pickle'.format(self.num_classes), 'wb') as p:\n","                pickle.dump(labels, p)\n","            print(\"finished generating all of datasets\")            \n","\n","        return np.array(imgs), np.array(labels)\n","\n","    def imread(self, path):\n","        return scipy.misc.imread(path, mode='RGB').astype(np.float)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yN_OC4bH8O4-"},"source":["class CGAN():\n","    def __init__(self, dataset_name=\"mnist\"):\n","        # Input shape\n","        self.img_rows = 28\n","        self.img_cols = 28\n","        self.dataset_name = dataset_name\n","        if self.dataset_name == \"mnist\":\n","            self.channels = 1\n","        else:\n","            self.channels = 3\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","        if self.dataset_name == \"mnist\":\n","            self.num_classes = 10\n","        elif self.dataset_name == \"foodimg\":\n","            self.num_classes = 20\n","        self.latent_dim = 100\n","\n","        self.data_loader = DataLoader(num_classes=self.num_classes,\n","                                      img_res=(self.img_rows, self.img_cols))\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # Build and compile the discriminator\n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.compile(loss=['binary_crossentropy'],\n","                                   optimizer=optimizer,\n","                                   metrics=['accuracy'])\n","\n","        # Build the generator\n","        self.generator = self.build_generator()\n","\n","        # The generator takes noise and the target label as input\n","        # and generates the corresponding digit of that label\n","        noise = Input(shape=(self.latent_dim,))\n","        label = Input(shape=(1,))\n","        img = self.generator([noise, label])\n","\n","        # For the combined model we will only train the generator\n","        self.discriminator.trainable = False\n","\n","        # The discriminator takes generated image as input and determines validity\n","        # and the label of that image\n","        valid = self.discriminator([img, label])\n","\n","        # The combined model  (stacked generator and discriminator)\n","        # Trains generator to fool discriminator\n","        self.combined = Model([noise, label], valid)\n","        self.combined.compile(loss=['binary_crossentropy'],\n","            optimizer=optimizer)\n","\n","    def build_generator(self):\n","\n","        model = Sequential()\n","\n","        model.add(Dense(256, input_dim=self.latent_dim))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dense(512))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dense(1024))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n","        model.add(Reshape(self.img_shape))\n","\n","        # model.summary()\n","\n","        noise = Input(shape=(self.latent_dim,))\n","        label = Input(shape=(1,), dtype='int32')\n","        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n","\n","        model_input = multiply([noise, label_embedding])\n","        img = model(model_input)\n","\n","        return Model([noise, label], img)\n","\n","    def build_discriminator(self):\n","\n","        model = Sequential()\n","\n","        model.add(Dense(512, input_dim=np.prod(self.img_shape)))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dense(512))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.4))\n","        model.add(Dense(512))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.4))\n","        model.add(Dense(1, activation='sigmoid'))\n","        # model.summary()\n","\n","        img = Input(shape=self.img_shape)\n","        label = Input(shape=(1,), dtype='int32')\n","\n","        label_embedding = Flatten()(Embedding(self.num_classes, np.prod(self.img_shape))(label))\n","        flat_img = Flatten()(img)\n","\n","        model_input = multiply([flat_img, label_embedding])\n","\n","        validity = model(model_input)\n","\n","        return Model([img, label], validity)\n","\n","    def train(self, epochs, batch_size=128, sample_interval=50):\n","\n","        if self.dataset_name == \"mnist\":\n","            (X_train, y_train), (_, _) = mnist.load_data()\n","            # Configure input\n","            X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n","            X_train = np.expand_dims(X_train, axis=3)\n","        else:\n","            X_train, y_train = self.data_loader.load_data()\n","            X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n","      \n","        y_train = y_train.reshape(-1, 1)\n","\n","        # Adversarial ground truths\n","        valid = np.ones((batch_size, 1))\n","        fake = np.zeros((batch_size, 1))\n","\n","        for epoch in range(epochs):\n","\n","            # ---------------------\n","            #  Train Discriminator\n","            # ---------------------\n","\n","            # Select a random half batch of images\n","            idx = np.random.randint(0, X_train.shape[0], batch_size)\n","            imgs, labels = X_train[idx], y_train[idx]\n","\n","            # Sample noise as generator input\n","            noise = np.random.normal(0, 1, (batch_size, 100))\n","\n","            # Generate a half batch of new images\n","            gen_imgs = self.generator.predict([noise, labels])\n","\n","            # Train the discriminator\n","            d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)\n","            d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","            # ---------------------\n","            #  Train Generator\n","            # ---------------------\n","\n","            # Condition on labels \n","            sampled_labels = np.random.randint(0, self.num_classes, batch_size).reshape(-1, 1)\n","\n","            # Train the generator\n","            g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n","\n","            # If at save interval => save generated image samples\n","            if epoch % sample_interval == 0:\n","               # Plot the progress\n","                print(\"epoch %d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch+1, d_loss[0], 100*d_loss[1], g_loss))\n","                self.sample_images(epoch)\n","\n","    def sample_images(self, epoch):\n","        os.makedirs('../result/%s/cgan' % self.dataset_name, exist_ok=True)\n","\n","        food_list = [\"bibimba\", \"chahan\", \"chikenrice\", \"curry\", \"ebichill\", \n","                      \"gratin\", \"gyudon\", \"hiyachu\", \"kaisendon\", \"katsudon\", \n","                      \"meatspa\", \"omelet\", \"omurice\", \"oyakodon\", \"pilaf\", \"pizza\", \n","                      \"ramen\", \"rice\", \"soba\", \"steak\"]\n","\n","        if self.dataset_name == \"mnist\":\n","            r, c = 2, 5\n","            noise = np.random.normal(0, 1, (r * c, 100))\n","        else:\n","            r, c = 4, 5\n","            noise = np.random.normal(0, 1, (r * c, 100))\n","        \n","        sampled_labels = np.arange(0, self.num_classes).reshape(-1, 1)\n","        gen_imgs = self.generator.predict([noise, sampled_labels])\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        fig, axs = plt.subplots(r, c, figsize=(10, 10))\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                if self.dataset_name == \"mnist\":\n","                    axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n","                    axs[i,j].set_title(\"digit : %d\" % sampled_labels[cnt])\n","                elif self.dataset_name == \"foodimg\":\n","                    axs[i,j].imshow(gen_imgs[cnt,:,:,:])\n","                    axs[i,j].set_title(\"{}\".format(food_list[cnt]))\n","                axs[i,j].axis('off')\n","                cnt += 1\n","        fig.savefig(\"../result/{}/cgan/epoch{}.png\".format(self.dataset_name, epoch),\n","                    transparent=True, dpi=300, bbox_inches=\"tight\", pad_inches=0.0)\n","        plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9DD8Zz4O1Sv","colab":{"base_uri":"https://localhost:8080/","height":758},"executionInfo":{"status":"error","timestamp":1612594850055,"user_tz":-540,"elapsed":665618,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}},"outputId":"8642ca4c-789f-483c-f96a-38b53e47d243"},"source":["cgan = CGAN(dataset_name=\"foodimg\")\n","#cgan = CGAN(dataset_name=\"mnist\")\n","cgan.train(epochs=500000, batch_size=32, sample_interval=10000)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["epoch 1 [D loss: 0.693727, acc.: 31.25%] [G loss: 0.676793]\n","epoch 10001 [D loss: 0.672554, acc.: 46.88%] [G loss: 0.707860]\n","epoch 20001 [D loss: 0.717961, acc.: 45.31%] [G loss: 0.805275]\n","epoch 30001 [D loss: 0.692158, acc.: 46.88%] [G loss: 0.851080]\n","epoch 40001 [D loss: 0.631641, acc.: 62.50%] [G loss: 0.808809]\n","epoch 50001 [D loss: 0.654302, acc.: 59.38%] [G loss: 0.854447]\n","epoch 60001 [D loss: 0.614031, acc.: 62.50%] [G loss: 0.910921]\n","epoch 70001 [D loss: 0.654013, acc.: 53.12%] [G loss: 0.961875]\n","epoch 80001 [D loss: 0.504565, acc.: 81.25%] [G loss: 0.895734]\n","epoch 90001 [D loss: 0.638280, acc.: 64.06%] [G loss: 0.989370]\n","epoch 100001 [D loss: 0.628344, acc.: 60.94%] [G loss: 0.975713]\n","epoch 110001 [D loss: 0.517963, acc.: 76.56%] [G loss: 1.074201]\n","epoch 120001 [D loss: 0.620235, acc.: 60.94%] [G loss: 0.937835]\n","epoch 130001 [D loss: 0.599234, acc.: 64.06%] [G loss: 1.104290]\n","epoch 140001 [D loss: 0.524435, acc.: 73.44%] [G loss: 1.224781]\n","epoch 150001 [D loss: 0.630569, acc.: 67.19%] [G loss: 1.295916]\n","epoch 160001 [D loss: 0.488611, acc.: 73.44%] [G loss: 1.255010]\n","epoch 170001 [D loss: 0.516764, acc.: 75.00%] [G loss: 1.224102]\n","epoch 180001 [D loss: 0.516370, acc.: 71.88%] [G loss: 1.213553]\n","epoch 190001 [D loss: 0.432186, acc.: 82.81%] [G loss: 1.370429]\n","epoch 200001 [D loss: 0.585914, acc.: 68.75%] [G loss: 1.349020]\n","epoch 210001 [D loss: 0.449520, acc.: 82.81%] [G loss: 1.355936]\n","epoch 220001 [D loss: 0.372094, acc.: 85.94%] [G loss: 1.410067]\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-9756a02ff7db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"foodimg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#cgan = CGAN(dataset_name=\"mnist\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-6cc0f6ac3ec9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# Generate a half batch of new images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;31m# Train the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1623\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    703\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   2970\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 2972\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   2973\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}