{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dcgan.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Vg1AlV6E9OPO"},"source":["* DCGAN使ってグラタンに似た偽画像を生成する"]},{"cell_type":"code","metadata":{"id":"eadlGD1i9Pl2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605993711056,"user_tz":-540,"elapsed":550,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}},"outputId":"6eef524a-255e-4a48-82c7-01bce89ece83"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3P0o6AYW9PnR","executionInfo":{"status":"ok","timestamp":1605993711289,"user_tz":-540,"elapsed":773,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}}},"source":["# カレントディレクトリの読み込みとカレントディレクトリへの移動\n","import sys\n","sys.path.append(f'/content/drive/My Drive/system/')\n","import os\n","os.chdir(f'/content/drive/My Drive/system/myanswer')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"5TbD7gAHz9DX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605993714774,"user_tz":-540,"elapsed":4253,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}},"outputId":"0c3db323-3bcd-4f75-a4bc-9db5ed585411"},"source":["!pip install git+https://www.github.com/keras-team/keras-contrib.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting git+https://www.github.com/keras-team/keras-contrib.git\n","  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-hdnt_2wb\n","  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-hdnt_2wb\n","Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /usr/local/lib/python3.6/dist-packages\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.4.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras->keras-contrib==2.0.8) (1.15.0)\n","Building wheels for collected packages: keras-contrib\n","  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101066 sha256=dcd5c8c9c6622d329e8931be29be4f3ca3ba3e4d2a2c005042abc4ec9e09f13a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-70sfarm0/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n","Successfully built keras-contrib\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jsxpikwhmVKb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605993716791,"user_tz":-540,"elapsed":6263,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}},"outputId":"594bfaf0-4980-478c-b555-1293af9c0938"},"source":["!pip install scipy==1.1.0"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n5nZJvl19Ppy","executionInfo":{"status":"ok","timestamp":1605993718394,"user_tz":-540,"elapsed":7861,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}}},"source":["from __future__ import print_function, division\n","from keras.datasets import mnist\n","from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","from glob import glob\n","from skimage.transform import resize \n","import datetime\n","import pickle\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import scipy\n","import scipy.misc\n","import imageio"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"bf9cxyLT9PtK","executionInfo":{"status":"ok","timestamp":1605993718397,"user_tz":-540,"elapsed":7859,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}}},"source":["class DataLoader():\n","    def __init__(self, dataset_name, img_res=(128, 128)):\n","        self.dataset_name = dataset_name\n","        self.img_res = img_res\n","\n","    def load_data(self, is_testing=False):\n","        if os.path.exists(\"../pickle/{}_tensor.pickle\".format(self.dataset_name)):\n","            with open(\"../pickle/{}_tensor.pickle\".format(self.dataset_name), 'rb') as p:\n","                imgs = pickle.load(p)\n","        else:\n","            img_pathes = glob('../figure/foodimg128/%s/*.jpg' % (self.dataset_name))\n","            imgs = []\n","            for img_path in img_pathes:\n","                img = self.imread(img_path)\n","                if not is_testing:\n","                    img = scipy.misc.imresize(img, self.img_res)\n","                    if np.random.random() > 0.5:\n","                        img = np.fliplr(img)\n","                else:\n","                    img = scipy.misc.imresize(img, self.img_res)\n","                imgs.append(img)\n","            with open('../pickle/{}_tensor.pickle'.format(self.dataset_name), 'wb') as p:\n","                pickle.dump(imgs , p)\n","\n","        return np.array(imgs)\n","\n","    def imread(self, path):\n","        return scipy.misc.imread(path, mode=\"RGB\").astype(np.float)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"sSIkUznf-iNX","executionInfo":{"status":"ok","timestamp":1605993718741,"user_tz":-540,"elapsed":8198,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}}},"source":["class DCGAN():\n","    def __init__(self, dataset_name=\"mnist\"):\n","        # Input shape\n","        self.img_rows = 28\n","        self.img_cols = 28\n","        # 変換させたい画像のデータセットの名前を指定\n","        self.dataset_name = dataset_name\n","        if self.dataset_name == \"mnist\":\n","            self.channels = 1\n","        else:\n","            self.channels = 3\n","\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","        self.latent_dim = 100\n","\n","        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n","                                      img_res=(self.img_rows, self.img_cols))\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # Build and compile the discriminator\n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.compile(loss='binary_crossentropy',\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        # Build the generator\n","        self.generator = self.build_generator()\n","\n","        # The generator takes noise as input and generates imgs\n","        z = Input(shape=(self.latent_dim,))\n","        img = self.generator(z)\n","      \n","\n","        # For the combined model we will only train the generator\n","        self.discriminator.trainable = False\n","\n","        # The discriminator takes generated images as input and determines validity\n","        valid = self.discriminator(img)\n","\n","        # The combined model  (stacked generator and discriminator)\n","        # Trains the generator to fool the discriminator\n","        self.combined = Model(z, valid)\n","        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n","\n","\n","    def build_generator(self):\n","\n","        model = Sequential()\n","\n","        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n","        model.add(Reshape((7, 7, 128)))\n","        model.add(UpSampling2D())\n","        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Activation(\"relu\"))\n","        model.add(UpSampling2D())\n","        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n","        model.add(Activation(\"tanh\"))\n","\n","        noise = Input(shape=(self.latent_dim,))\n","        img = model(noise)\n","\n","        return Model(noise, img)\n","\n","    def build_discriminator(self):\n","\n","        model = Sequential()\n","        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.25))\n","        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n","        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.25))\n","        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.25))\n","        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.25))\n","        model.add(Flatten())\n","        model.add(Dense(1, activation='sigmoid'))\n","\n","        img = Input(shape=self.img_shape)\n","        validity = model(img)\n","\n","        return Model(img, validity)\n","\n","    def train(self, epochs, batch_size=128, save_interval=50):\n","\n","        if self.dataset_name == \"mnist\":\n","            (X_train, _), (_, _) = mnist.load_data()\n","            # Rescale -1 to 1\n","            X_train = X_train / 127.5 - 1.\n","            X_train = np.expand_dims(X_train, axis=3)\n","        else:\n","            X_train = self.data_loader.load_data()\n","            # Rescale -1 to 1\n","            X_train = X_train / 127.5 - 1.\n","\n","\n","        # Adversarial ground truths\n","        valid = np.ones((batch_size, 1))\n","        fake = np.zeros((batch_size, 1))\n","\n","        for epoch in range(epochs):\n","\n","            # ---------------------\n","            #  Train Discriminator\n","            # ---------------------\n","\n","            # Select a random half of images\n","            idx = np.random.randint(0, X_train.shape[0], batch_size)\n","            imgs = X_train[idx]\n","          \n","            # Sample noise and generate a batch of new images\n","            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","            gen_imgs = self.generator.predict(noise)\n","        \n","\n","            # Train the discriminator (real classified as ones and generated as zeros)\n","            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n","            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","            # ---------------------\n","            #  Train Generator\n","            # ---------------------\n","\n","            # Train the generator (wants discriminator to mistake images as real)\n","            g_loss = self.combined.train_on_batch(noise, valid)\n","      \n","            # If at save interval => save generated image samples\n","            if epoch % save_interval == 0:\n","                # Plot the progress\n","                print(\"epoch %d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch+1, d_loss[0], 100*d_loss[1], g_loss))\n","                self.save_imgs(epoch)\n","\n","    def save_imgs(self, epoch):\n","        os.makedirs('../result/%s/dcgan' % self.dataset_name, exist_ok=True)\n","        r, c = 5, 5\n","        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n","        gen_imgs = self.generator.predict(noise)\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                if self.dataset_name == \"mnist\":\n","                    axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap=\"grey\")\n","                else:\n","                    axs[i,j].imshow(gen_imgs[cnt,:,:,:])\n","                axs[i,j].axis('off')\n","                cnt += 1\n","        fig.savefig(\"../result/{}/dcgan/epoch{}.png\".format(self.dataset_name, epoch),\n","                     transparent=True, dpi=300, bbox_inches=\"tight\", pad_inches=0.0)\n","        plt.close()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"SktavMou1UmC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605996615705,"user_tz":-540,"elapsed":2905157,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}},"outputId":"c7ce0de8-7377-46c6-d3b4-a5824065e62d"},"source":["dcgan = DCGAN(dataset_name=\"gratin\")\n","# dcgan = DCGAN(dataset_name=\"mnist\")\n","dcgan.train(epochs=50000, batch_size=32, save_interval=5000)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["epoch 1 [D loss: 0.899147, acc.: 42.19%] [G loss: 0.731866]\n","epoch 5001 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.008732]\n","epoch 10001 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.000109]\n","epoch 15001 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.000023]\n","epoch 20001 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.000003]\n","epoch 25001 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.000001]\n","epoch 30001 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.000003]\n","epoch 35001 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.000006]\n","epoch 40001 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.000003]\n","epoch 45001 [D loss: 0.000000, acc.: 100.00%] [G loss: 0.000038]\n"],"name":"stdout"}]}]}