{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"wgan.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"15Kn3UGC4eN4"},"source":["* WGAN使ってグラタンに似た偽画像を生成する"]},{"cell_type":"code","metadata":{"id":"MhoAPmH54hX-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605981471729,"user_tz":-540,"elapsed":27437,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}},"outputId":"da3efb43-5b01-42ac-a6f6-de60834a4c65"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FVSYCbUl4hZy","executionInfo":{"status":"ok","timestamp":1605981471732,"user_tz":-540,"elapsed":27434,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}}},"source":["# カレントディレクトリの読み込みとカレントディレクトリへの移動\n","import sys\n","sys.path.append(f'/content/drive/My Drive/system/')\n","import os\n","os.chdir(f'/content/drive/My Drive/system/myanswer')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"QS-dRMhF4hf3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605981483592,"user_tz":-540,"elapsed":39287,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}},"outputId":"326361a9-e53c-455a-ea0f-3043db446ca7"},"source":["!pip install scipy==1.1.0"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting scipy==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n","\u001b[K     |████████████████████████████████| 31.2MB 108kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.5)\n","\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.3.0 has requirement scipy==1.4.1, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: scipy\n","  Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","Successfully installed scipy-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B1kfwDjm4hjY","executionInfo":{"status":"ok","timestamp":1605981485175,"user_tz":-540,"elapsed":40866,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}}},"source":["from __future__ import print_function, division\n","\n","from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import RMSprop\n","from functools import partial\n","from glob import glob\n","import keras.backend as K\n","import tensorflow as tf\n","import scipy\n","import scipy.misc\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZG2QONAC4hcO","executionInfo":{"status":"ok","timestamp":1605981485182,"user_tz":-540,"elapsed":40870,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}}},"source":["class DataLoader():\n","    def __init__(self, dataset_name, img_res=(128, 128)):\n","        self.dataset_name = dataset_name\n","        self.img_res = img_res\n","\n","    def load_data(self, is_testing=False):\n","        if os.path.exists(\"../pickle/{}_tensor.pickle\".format(self.dataset_name)):\n","            with open(\"../pickle/{}_tensor.pickle\".format(self.dataset_name), 'rb') as p:\n","                imgs = pickle.load(p)\n","        else:\n","            img_pathes = glob('../figure/foodimg128/%s/*.jpg' % (self.dataset_name))\n","            imgs = []\n","            for img_path in img_pathes:\n","                img = self.imread(img_path)\n","                if not is_testing:\n","                    img = scipy.misc.imresize(img, self.img_res)\n","                    if np.random.random() > 0.5:\n","                        img = np.fliplr(img)\n","                else:\n","                    img = scipy.misc.imresize(img, self.img_res)\n","                imgs.append(img)\n","            with open('../pickle/{}_tensor.pickle'.format(self.dataset_name), 'wb') as p:\n","                pickle.dump(imgs , p)\n","\n","        return np.array(imgs)\n","\n","    def imread(self, path):\n","        return scipy.misc.imread(path, mode=\"RGB\").astype(np.float)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSb-5v1Z5pO5","executionInfo":{"status":"ok","timestamp":1605981485460,"user_tz":-540,"elapsed":41145,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}}},"source":["class WGAN():\n","    def __init__(self, dataset_name=\"mnist\"):\n","        self.img_rows = 28\n","        self.img_cols = 28\n","        # 変換させたい画像のデータセットの名前を指定\n","        self.dataset_name = dataset_name\n","        if self.dataset_name == \"mnist\":\n","            self.channels = 1\n","        else:\n","            self.channels = 3\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","        self.latent_dim = 100\n","\n","        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n","                                      img_res=(self.img_rows, self.img_cols))\n","\n","\n","        # Following parameter and optimizer set as recommended in paper\n","        self.n_critic = 5\n","        self.clip_value = 0.01\n","        optimizer = RMSprop(lr=0.00005)\n","\n","        # Build and compile the critic\n","        self.critic = self.build_critic()\n","        self.critic.compile(loss=self.wasserstein_loss,\n","                            optimizer=optimizer,\n","                            metrics=['accuracy'])\n","\n","        # Build the generator\n","        self.generator = self.build_generator()\n","\n","        # The generator takes noise as input and generated imgs\n","        z = Input(shape=(self.latent_dim,))\n","        img = self.generator(z)\n","\n","        # For the combined model we will only train the generator\n","        self.critic.trainable = False\n","\n","        # The critic takes generated images as input and determines validity\n","        valid = self.critic(img)\n","\n","        # The combined model  (stacked generator and critic)\n","        self.combined = Model(z, valid)\n","        self.combined.compile(loss=self.wasserstein_loss,\n","                              optimizer=optimizer,\n","                              metrics=['accuracy'])\n","    \n","\n","    def wasserstein_loss(self, y_true, y_pred):\n","        return K.mean(y_true * y_pred)\n","\n","    def build_generator(self):\n","        model = Sequential()\n","        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n","        model.add(Reshape((7, 7, 128)))\n","        model.add(UpSampling2D())\n","        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Activation(\"relu\"))\n","        model.add(UpSampling2D())\n","        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Activation(\"relu\"))\n","        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n","        model.add(Activation(\"tanh\"))\n","\n","        # model.summary()\n","\n","        noise = Input(shape=(self.latent_dim,))\n","        img = model(noise)\n","\n","        return Model(noise, img)\n","\n","    def build_critic(self):\n","        model = Sequential()\n","        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.25))\n","        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n","        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.25))\n","        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.25))\n","        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.25))\n","        model.add(Flatten())\n","        model.add(Dense(1))\n","\n","        # model.summary()\n","\n","        img = Input(shape=self.img_shape)\n","        validity = model(img)\n","\n","        return Model(img, validity)\n","    \n","    def train(self, epochs, batch_size, sample_interval=50):\n","\n","        if self.dataset_name == \"mnist\":\n","            (X_train, _), (_, _) = mnist.load_data()\n","            # Rescale -1 to 1\n","            X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n","            X_train = np.expand_dims(X_train, axis=3)\n","        else:\n","            X_train = self.data_loader.load_data()\n","            # Rescale -1 to 1\n","            X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n","\n","        # Adversarial ground truths\n","        valid = -np.ones((batch_size, 1))\n","        fake =  np.ones((batch_size, 1))\n","        \n","        for epoch in range(epochs):\n","            for _ in range(self.n_critic):\n","                # ---------------------\n","                #  Train Discriminator\n","                # ---------------------\n","\n","                # Select a random batch of images\n","                idx = np.random.randint(0, X_train.shape[0], batch_size)\n","                imgs = X_train[idx]\n","                \n","                # Sample noise as generator input\n","                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","\n","                # Generate a batch of new images\n","                gen_imgs = self.generator.predict(noise)\n","\n","                # Train the critic\n","                d_loss_real = self.critic.train_on_batch(imgs, valid)\n","                d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n","                d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n","\n","                # Clip critic weights\n","                for l in self.critic.layers:\n","                    weights = l.get_weights()\n","                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n","                    l.set_weights(weights)\n","\n","\n","            # ---------------------\n","            #  Train Generator\n","            # ---------------------\n","            g_loss = self.combined.train_on_batch(noise, valid)\n","\n","           \n","            # If at save interval => save generated image samples\n","            if epoch % sample_interval == 0:\n","                # Plot the progress\n","                print(\"epoch %d [D loss: %f] [G loss: %f]\" % (epoch+1, 1 - d_loss[0], 1 - g_loss[0]))\n","                self.sample_images(epoch)\n","\n","    def sample_images(self, epoch):\n","        os.makedirs('../result/%s/wgan' % self.dataset_name, exist_ok=True)\n","        r, c = 5, 5\n","        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n","        gen_imgs = self.generator.predict(noise)\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                if self.dataset_name == \"mnist\":\n","                    axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n","                else:\n","                    axs[i,j].imshow(gen_imgs[cnt,:,:,:])\n","                axs[i,j].axis('off')\n","                cnt += 1\n","        fig.savefig(\"../result/{}/wgan/epoch{}.png\".format(self.dataset_name, epoch),\n","                    transparent=True, dpi=300, bbox_inches=\"tight\", pad_inches=0.0)\n","        plt.close()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"jL02exdq5yrw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605998160604,"user_tz":-540,"elapsed":16716284,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}},"outputId":"9e693146-4103-4f43-e62e-d2dd6b4150d6"},"source":[" wgan = WGAN(dataset_name=\"gratin\")\n"," # wgan = WGAN(dataset_name=\"mnist\") \n"," wgan.train(epochs=50000, batch_size=32, sample_interval=5000)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["epoch 1 [D loss: 0.999906] [G loss: 1.000275]\n","epoch 5001 [D loss: 0.999967] [G loss: 1.000062]\n","epoch 10001 [D loss: 0.999953] [G loss: 1.000053]\n","epoch 15001 [D loss: 0.999976] [G loss: 1.000058]\n","epoch 20001 [D loss: 0.999978] [G loss: 1.000077]\n","epoch 25001 [D loss: 0.999975] [G loss: 1.000057]\n","epoch 30001 [D loss: 0.999963] [G loss: 1.000068]\n","epoch 35001 [D loss: 0.999965] [G loss: 1.000067]\n","epoch 40001 [D loss: 0.999967] [G loss: 1.000067]\n","epoch 45001 [D loss: 0.999974] [G loss: 1.000072]\n"],"name":"stdout"}]}]}