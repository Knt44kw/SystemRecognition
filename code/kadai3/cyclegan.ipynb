{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cyclegan.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Vlpgcc4XJDQn"},"source":["* CycleGANを用いてピラフからカレーライスへの画像変換を行う\n"]},{"cell_type":"code","metadata":{"id":"QC-OL61eJNly","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612522995430,"user_tz":-540,"elapsed":27375,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}},"outputId":"5c874007-d2a8-4a1c-9144-602dd7ed45d2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LjTnVXUYJY_a"},"source":["# カレントディレクトリの読み込みとカレントディレクトリへの移動\n","import sys\n","sys.path.append(f'/content/drive/My Drive/system/')\n","import os\n","os.chdir(f'/content/drive/My Drive/system/myanswer')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kdyuq9CVwhQD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612523000762,"user_tz":-540,"elapsed":32695,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}},"outputId":"8dd7b55f-a4b4-4ee9-cbd5-72572e153f6d"},"source":["!pip install git+https://www.github.com/keras-team/keras-contrib.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+https://www.github.com/keras-team/keras-contrib.git\n","  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-ln3kk7gc\n","  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-ln3kk7gc\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.4.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras->keras-contrib==2.0.8) (1.15.0)\n","Building wheels for collected packages: keras-contrib\n","  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101066 sha256=f8452e893b9ffe806457e01d19e1d46dc87748e7ee166fffaef17d18d669a340\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-6om21y48/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n","Successfully built keras-contrib\n","Installing collected packages: keras-contrib\n","Successfully installed keras-contrib-2.0.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VaG7zab7k12_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612523010751,"user_tz":-540,"elapsed":42677,"user":{"displayName":"Yoshikawa Kento","photoUrl":"","userId":"06659379309748930560"}},"outputId":"989fd797-fa79-44a7-f44b-bc3e3d4fc37f"},"source":["!pip install scipy==1.1.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting scipy==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n","\u001b[K     |████████████████████████████████| 31.2MB 100kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.19.5)\n","\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: scipy\n","  Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","Successfully installed scipy-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hMXkiZ9vKbgl"},"source":["from __future__ import print_function, division\n","\n","from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","from glob import glob\n","from PIL import Image\n","import datetime\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import scipy\n","import scipy.misc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2qRvQjm0fDBc"},"source":["class DataGenerator():\n","      \"\"\"\n","      source_nameで指定した画像(A)を target_nameで指定した画像(B)に変換する\n","      そのために，画像を収集し，AとBの画像を学習データとテストデータに分け\n","      それぞれ，学習データ用とテストデータ用のディレクトリに保存するクラス\n","      \"\"\"\n","      def __init__(self, source_name, target_name, dataset_name, img_res=(128, 128)):\n","        self.source_name = source_name\n","        self.target_name = target_name\n","        self.dataset_name = dataset_name \n","        self.img_res = img_res\n","\n","      def generate_data(self, indices=1000, train_percentage=0.8):\n","         \"\"\"\n","          画像の収集とCycleGANを実行するための画像パスを設定し，収集した画像を設定したパスへと保存するメソッド\n","\n","          indices(int): 画像枚数\n","          デフォルトでは，self.target_nameで指定した画像のうち\n","          8割 (train_percentage): 学習データ用の画像\n","          2割 : テストデータ用の画像\n","         \"\"\"\n","         os.makedirs('../figure/foodimg128/{}/trainA'.format(self.dataset_name), exist_ok=True)\n","         os.makedirs('../figure/foodimg128/{}/trainB'.format(self.dataset_name), exist_ok=True)\n","         os.makedirs('../figure/foodimg128/{}/testA'.format(self.dataset_name), exist_ok=True)\n","         os.makedirs('../figure/foodimg128/{}/testB'.format(self.dataset_name), exist_ok=True)\n","         \n","         # self.source_nameで指定された食事画像のパスを取得\n","         source_image_pathes = glob('../figure/foodimg128/{}/*.jpg'.format(self.source_name))\n","         # self.target_nameで指定された食事画像のパスを取得\n","         target_image_pathes = glob('../figure/foodimg128/{}/*.jpg'.format(self.target_name))\n","\n","         for index in range(indices):\n","            source_image = Image.open(source_image_pathes[index])\n","            target_image = Image.open(target_image_pathes[index])\n","            if indices * train_percentage <= index < indices:\n","                source_image.save(\"../figure/foodimg128/{}/testA/{}.jpg\".format(self.dataset_name, index)) # テストデータの保存\n","                target_image.save(\"../figure/foodimg128/{}/testB/{}.jpg\".format(self.dataset_name, index))\n","            else:\n","                source_image.save(\"../figure/foodimg128/{}/trainA/{}.jpg\".format(self.dataset_name, index)) # 学習データの保存\n","                target_image.save(\"../figure/foodimg128/{}/trainB/{}.jpg\".format(self.dataset_name, index))      "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H55KFwxE7Sv2"},"source":["class DataLoader():\n","    def __init__(self, dataset_name, img_res=(128, 128)):\n","        self.dataset_name = dataset_name\n","        self.img_res = img_res\n","\n","    def load_data(self, domain, batch_size=1, is_testing=False):\n","        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n","        path = glob('../figure/foodimg128/%s/%s/*.jpg' % (self.dataset_name, data_type))\n","\n","        batch_images = np.random.choice(path, size=batch_size)\n","\n","        imgs = []\n","        for img_path in batch_images:\n","            img = self.imread(img_path)\n","            if not is_testing:\n","                img = scipy.misc.imresize(img, self.img_res)\n","                if np.random.random() > 0.5:\n","                    img = np.fliplr(img)\n","            else:\n","                img = scipy.misc.imresize(img, self.img_res)\n","            imgs.append(img)\n","\n","        imgs = np.array(imgs)/127.5 - 1.\n","\n","        return imgs\n","\n","    def load_batch(self, batch_size=1, is_testing=False):\n","        data_type = \"train\" if not is_testing else \"test\"\n","        path_A = glob('../figure/foodimg128/%s/%sA/*.jpg' % (self.dataset_name, data_type))\n","        path_B = glob('../figure/foodimg128/%s/%sB/*.jpg' % (self.dataset_name, data_type))\n","\n","        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n","        total_samples = self.n_batches * batch_size\n","\n","        # Sample n_batches * batch_size from each path list so that model sees all\n","        # samples from both domains\n","        path_A = np.random.choice(path_A, total_samples, replace=False)\n","        path_B = np.random.choice(path_B, total_samples, replace=False)\n","\n","        for i in range(self.n_batches-1):\n","            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n","            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n","            imgs_A, imgs_B = [], []\n","            for img_A, img_B in zip(batch_A, batch_B):\n","                img_A = self.imread(img_A)\n","                img_B = self.imread(img_B)\n","                \n","\n","                img_A = scipy.misc.imresize(img_A, self.img_res)\n","                img_B = scipy.misc.imresize(img_B, self.img_res)\n","\n","                if not is_testing and np.random.random() > 0.5:\n","                        img_A = np.fliplr(img_A)\n","                        img_B = np.fliplr(img_B)\n","\n","                imgs_A.append(img_A)\n","                imgs_B.append(img_B)\n","\n","            imgs_A = np.array(imgs_A)/127.5 - 1.\n","            imgs_B = np.array(imgs_B)/127.5 - 1.\n","\n","            yield imgs_A, imgs_B\n","\n","    def load_img(self, path):\n","        img = self.imread(path)\n","        img = scipy.misc.imresize(img, self.img_res)\n","        img = img/127.5 - 1.\n","        return img[np.newaxis, :, :, :]\n","\n","    def imread(self, path):\n","        return scipy.misc.imread(path, mode='RGB').astype(np.float)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-GGuWiJFkEe"},"source":["class CycleGAN():\n","    def __init__(self):\n","        # Number of images (簡単のため，入力に使う画像枚数を既知であることが前提)\n","        self.image_num = 2000\n","        # Input shape\n","        self.img_rows = 128\n","        self.img_cols = 128\n","        self.channels = 3\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","\n","        # Configure data loader\n","        # ピラフからカレーへの画像変換を行う\n","        self.dataset_name = 'pilaf2curry'\n","        self.source_name = \"pilaf\"\n","        self.target_name = \"curry\"\n","        \n","        self.data_generator = DataGenerator(source_name=self.source_name,\n","                                            target_name=self.target_name, \n","                                            dataset_name=self.dataset_name, \n","                                            img_res=(self.img_rows, self.img_cols))\n","        \n","        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n","                                      img_res=(self.img_rows, self.img_cols))\n","\n","\n","        # Calculate output shape of D (PatchGAN)\n","        patch = int(self.img_rows / 2**4)\n","        self.disc_patch = (patch, patch, 1)\n","\n","        # Number of filters in the first layer of G and D\n","        self.gf = 32\n","        self.df = 64\n","\n","        # Loss weights\n","        self.lambda_cycle = 10.0                    # Cycle-consistency loss\n","        self.lambda_id = 0.1 * self.lambda_cycle    # Identity loss\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # Build and compile the discriminators\n","        self.d_A = self.build_discriminator()\n","        self.d_B = self.build_discriminator()\n","        self.d_A.compile(loss='mse',\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","        self.d_B.compile(loss='mse',\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        #-------------------------\n","        # Construct Computational\n","        #   Graph of Generators\n","        #-------------------------\n","\n","        # Build the generators\n","        self.g_AB = self.build_generator()\n","        self.g_BA = self.build_generator()\n","\n","        # Input images from both domains\n","        img_A = Input(shape=self.img_shape)\n","        img_B = Input(shape=self.img_shape)\n","\n","        # Translate images to the other domain\n","        fake_B = self.g_AB(img_A)\n","        fake_A = self.g_BA(img_B)\n","        # Translate images back to original domain\n","        reconstr_A = self.g_BA(fake_B)\n","        reconstr_B = self.g_AB(fake_A)\n","        # Identity mapping of images\n","        img_A_id = self.g_BA(img_A)\n","        img_B_id = self.g_AB(img_B)\n","\n","        # For the combined model we will only train the generators\n","        self.d_A.trainable = False\n","        self.d_B.trainable = False\n","\n","        # Discriminators determines validity of translated images\n","        valid_A = self.d_A(fake_A)\n","        valid_B = self.d_B(fake_B)\n","\n","        # Combined model trains generators to fool discriminators\n","        self.combined = Model(inputs=[img_A, img_B],\n","                              outputs=[ valid_A, valid_B,\n","                                        reconstr_A, reconstr_B,\n","                                        img_A_id, img_B_id ])\n","        self.combined.compile(loss=['mse', 'mse',\n","                                    'mae', 'mae',\n","                                    'mae', 'mae'],\n","                            loss_weights=[  1, 1,\n","                                            self.lambda_cycle, self.lambda_cycle,\n","                                            self.lambda_id, self.lambda_id ],\n","                            optimizer=optimizer)\n","\n","    def build_generator(self):\n","        \"\"\"U-Net Generator\"\"\"\n","\n","        def conv2d(layer_input, filters, f_size=4):\n","            \"\"\"Layers used during downsampling\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            d = InstanceNormalization()(d)\n","            return d\n","\n","        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n","            \"\"\"Layers used during upsampling\"\"\"\n","            u = UpSampling2D(size=2)(layer_input)\n","            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n","            if dropout_rate:\n","                u = Dropout(dropout_rate)(u)\n","            u = InstanceNormalization()(u)\n","            u = Concatenate()([u, skip_input])\n","            return u\n","\n","        # Image input\n","        d0 = Input(shape=self.img_shape)\n","\n","        # Downsampling\n","        d1 = conv2d(d0, self.gf)\n","        d2 = conv2d(d1, self.gf*2)\n","        d3 = conv2d(d2, self.gf*4)\n","        d4 = conv2d(d3, self.gf*8)\n","\n","        # Upsampling\n","        u1 = deconv2d(d4, d3, self.gf*4)\n","        u2 = deconv2d(u1, d2, self.gf*2)\n","        u3 = deconv2d(u2, d1, self.gf)\n","\n","        u4 = UpSampling2D(size=2)(u3)\n","        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n","\n","        return Model(d0, output_img)\n","\n","    def build_discriminator(self):\n","\n","        def d_layer(layer_input, filters, f_size=4, normalization=True):\n","            \"\"\"Discriminator layer\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            if normalization:\n","                d = InstanceNormalization()(d)\n","            return d\n","\n","        img = Input(shape=self.img_shape)\n","\n","        d1 = d_layer(img, self.df, normalization=False)\n","        d2 = d_layer(d1, self.df*2)\n","        d3 = d_layer(d2, self.df*4)\n","        d4 = d_layer(d3, self.df*8)\n","\n","        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n","\n","        return Model(img, validity)\n","\n","    def generate_dataset(self):\n","        partitions = [\"trainA\", \"trainB\", \"testA\", \"testB\"]\n","        total_images = 0\n","          \n","        for partition in partitions:\n","            images_each_partition = os.listdir(\"../figure/foodimg128/{}/{}\".format(self.dataset_name, partition))\n","            total_images += len(images_each_partition)\n","\n","        if total_images == self.image_num:\n","            return\n","        else:\n","            self.data_generator.generate_data()\n","\n","    def train(self, epochs, batch_size=1, sample_interval=50):\n","\n","        start_time = datetime.datetime.now()\n","\n","        # Generate data for cyclegan\n","        self.generate_dataset()\n","\n","        # Adversarial loss ground truths\n","        valid = np.ones((batch_size,) + self.disc_patch)\n","        fake = np.zeros((batch_size,) + self.disc_patch)\n","\n","        for epoch in range(epochs):\n","            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n","                # ----------------------\n","                #  Train Discriminators\n","                # ----------------------\n","\n","                # Translate images to opposite domain\n","                fake_B = self.g_AB.predict(imgs_A)\n","                fake_A = self.g_BA.predict(imgs_B)\n","\n","                # Train the discriminators (original images = real / translated = Fake)\n","                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n","                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n","                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n","\n","                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n","                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n","                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n","\n","                # Total disciminator loss\n","                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n","\n","\n","                # ------------------\n","                #  Train Generators\n","                # ------------------\n","\n","                # Train the generators\n","                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n","                                                      [valid, valid,\n","                                                       imgs_A, imgs_B,\n","                                                       imgs_A, imgs_B])\n","\n","                elapsed_time = datetime.datetime.now() - start_time\n","\n","             \n","                # If at save interval => save generated image samples\n","                if batch_i % sample_interval == 0:\n","                    self.sample_images(epoch, batch_i)\n","                    # Plot the progress\n","                    print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" \\\n","                                                                        % ( epoch+1, epochs,\n","                                                                          batch_i+1, self.data_loader.n_batches,\n","                                                                          d_loss[0], 100*d_loss[1],\n","                                                                          g_loss[0],\n","                                                                          np.mean(g_loss[1:3]),\n","                                                                          np.mean(g_loss[3:5]),\n","                                                                          np.mean(g_loss[5:6]),\n","                                                                          elapsed_time))\n","                \n","                elif batch_i + 2  == self.data_loader.n_batches:\n","                    self.sample_images(epoch, batch_i)\n","                    # Plot the progress\n","                    print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" \\\n","                                                                        % ( epoch+1, epochs,\n","                                                                          batch_i+1, self.data_loader.n_batches,\n","                                                                          d_loss[0], 100*d_loss[1],\n","                                                                          g_loss[0],\n","                                                                          np.mean(g_loss[1:3]),\n","                                                                          np.mean(g_loss[3:5]),\n","                                                                          np.mean(g_loss[5:6]),\n","                                                                          elapsed_time))\n","\n","\n","    def sample_images(self, epoch, batch_i):\n","        os.makedirs('../result/%s' % self.dataset_name, exist_ok=True)\n","        r, c = 2, 3\n","\n","        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n","        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n","\n","        # Translate images to the other domain\n","        fake_B = self.g_AB.predict(imgs_A)\n","        fake_A = self.g_BA.predict(imgs_B)\n","        # Translate back to original domain\n","        reconstr_A = self.g_BA.predict(fake_B)\n","        reconstr_B = self.g_AB.predict(fake_A)\n","\n","        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        titles = ['Original', 'Translated', 'Reconstructed']\n","        fig, axs = plt.subplots(r, c, figsize=(10, 10))\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i,j].imshow(gen_imgs[cnt])\n","                axs[i, j].set_title(titles[j])\n","                axs[i,j].axis('off')\n","                cnt += 1\n","        fig.savefig(\"../result/{}/epoch{}_imageid{}.png\".format(self.dataset_name, epoch+1, batch_i),\n","                     transparent=True, dpi=300, bbox_inches=\"tight\", pad_inches=0.0)\n","        if batch_i + 2 == self.data_loader.n_batches:\n","            fig.savefig(\"../result/{}/epoch{}_imageid{}.png\".format(self.dataset_name, epoch+1, batch_i+2),\n","                        transparent=True, dpi=300, bbox_inches=\"tight\", pad_inches=0.0)\n","        plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gEH_69mvY0M2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6a6c1ba6-1ba2-4d40-f126-9b4211b5a1ee"},"source":["cyclegan = CycleGAN()\n","cyclegan.train(epochs=200, batch_size=1, sample_interval=200)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:71: DeprecationWarning:     `imread` is deprecated!\n","    `imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","    Use ``imageio.imread`` instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: DeprecationWarning:     `imresize` is deprecated!\n","    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","    Use ``skimage.transform.resize`` instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: DeprecationWarning:     `imresize` is deprecated!\n","    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","    Use ``skimage.transform.resize`` instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: DeprecationWarning:     `imresize` is deprecated!\n","    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","    Use ``skimage.transform.resize`` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["[Epoch 1/1000] [Batch 1/800] [D loss: 16.744996, acc:  33%] [G loss: 79.088791, adv: 28.967282, recon: 0.968649, id: 1.042343] time: 0:00:34.424808 \n","[Epoch 1/1000] [Batch 201/800] [D loss: 0.159293, acc:  76%] [G loss: 7.526360, adv: 0.846814, recon: 0.206265, id: 0.574997] time: 0:03:13.819964 \n","[Epoch 1/1000] [Batch 401/800] [D loss: 0.208001, acc:  60%] [G loss: 5.379257, adv: 0.609793, recon: 0.132221, id: 0.383562] time: 0:05:29.066955 \n","[Epoch 1/1000] [Batch 601/800] [D loss: 0.263280, acc:  51%] [G loss: 5.735487, adv: 0.597524, recon: 0.136400, id: 0.682430] time: 0:07:43.951798 \n","[Epoch 1/1000] [Batch 799/800] [D loss: 0.137236, acc:  81%] [G loss: 5.370963, adv: 0.708084, recon: 0.111999, id: 0.682203] time: 0:09:56.322172 \n","[Epoch 2/1000] [Batch 1/800] [D loss: 0.393398, acc:  39%] [G loss: 6.163262, adv: 0.681187, recon: 0.163701, id: 0.420512] time: 0:09:59.223762 \n","[Epoch 2/1000] [Batch 201/800] [D loss: 0.200440, acc:  67%] [G loss: 5.350718, adv: 0.661782, recon: 0.119107, id: 0.621795] time: 0:10:33.833900 \n","[Epoch 2/1000] [Batch 401/800] [D loss: 0.183247, acc:  66%] [G loss: 5.707959, adv: 0.668630, recon: 0.125047, id: 0.778275] time: 0:11:08.314784 \n","[Epoch 2/1000] [Batch 601/800] [D loss: 0.099929, acc:  91%] [G loss: 6.683336, adv: 0.842344, recon: 0.153502, id: 0.697591] time: 0:11:43.585933 \n","[Epoch 2/1000] [Batch 799/800] [D loss: 0.209851, acc:  67%] [G loss: 5.676285, adv: 0.626525, recon: 0.137746, id: 0.580422] time: 0:12:18.583054 \n","[Epoch 3/1000] [Batch 1/800] [D loss: 0.129402, acc:  85%] [G loss: 5.761826, adv: 0.650407, recon: 0.139884, id: 0.587924] time: 0:12:21.509995 \n","[Epoch 3/1000] [Batch 201/800] [D loss: 0.332424, acc:  45%] [G loss: 5.355883, adv: 0.353621, recon: 0.138066, id: 0.784790] time: 0:12:57.041505 \n","[Epoch 3/1000] [Batch 401/800] [D loss: 0.068416, acc:  99%] [G loss: 6.354814, adv: 0.892885, recon: 0.142699, id: 0.756301] time: 0:13:31.297407 \n","[Epoch 3/1000] [Batch 601/800] [D loss: 0.272403, acc:  48%] [G loss: 4.501128, adv: 0.443538, recon: 0.106101, id: 0.433057] time: 0:14:06.724492 \n","[Epoch 3/1000] [Batch 799/800] [D loss: 0.194793, acc:  72%] [G loss: 5.597243, adv: 0.645932, recon: 0.122007, id: 0.898920] time: 0:14:41.032939 \n","[Epoch 4/1000] [Batch 1/800] [D loss: 0.075047, acc:  96%] [G loss: 4.960623, adv: 0.696778, recon: 0.090314, id: 0.739959] time: 0:14:43.926499 \n","[Epoch 4/1000] [Batch 201/800] [D loss: 0.089585, acc:  92%] [G loss: 5.991672, adv: 0.912596, recon: 0.132982, id: 0.469620] time: 0:15:18.775873 \n","[Epoch 4/1000] [Batch 401/800] [D loss: 0.077817, acc:  96%] [G loss: 5.353267, adv: 0.757473, recon: 0.109198, id: 0.572383] time: 0:15:53.365403 \n","[Epoch 4/1000] [Batch 601/800] [D loss: 0.358092, acc:  46%] [G loss: 5.692095, adv: 0.668079, recon: 0.123501, id: 0.697875] time: 0:16:27.964908 \n","[Epoch 4/1000] [Batch 799/800] [D loss: 0.020099, acc: 100%] [G loss: 6.095469, adv: 0.951041, recon: 0.138403, id: 0.419481] time: 0:17:02.756249 \n","[Epoch 5/1000] [Batch 1/800] [D loss: 0.210985, acc:  57%] [G loss: 6.320189, adv: 1.154634, recon: 0.125333, id: 0.396745] time: 0:17:05.485894 \n","[Epoch 5/1000] [Batch 201/800] [D loss: 0.016525, acc: 100%] [G loss: 8.105151, adv: 1.096839, recon: 0.208016, id: 0.529107] time: 0:17:40.773304 \n","[Epoch 5/1000] [Batch 401/800] [D loss: 0.079128, acc:  95%] [G loss: 6.154410, adv: 1.010741, recon: 0.131687, id: 0.464307] time: 0:18:16.042604 \n","[Epoch 5/1000] [Batch 601/800] [D loss: 0.057031, acc:  98%] [G loss: 5.219335, adv: 0.799406, recon: 0.110117, id: 0.353330] time: 0:18:50.462598 \n","[Epoch 5/1000] [Batch 799/800] [D loss: 0.142912, acc:  92%] [G loss: 6.640016, adv: 1.064135, recon: 0.138399, id: 0.674949] time: 0:19:24.541307 \n","[Epoch 6/1000] [Batch 1/800] [D loss: 0.072729, acc:  90%] [G loss: 5.961092, adv: 0.992298, recon: 0.119664, id: 0.539743] time: 0:19:27.540115 \n","[Epoch 6/1000] [Batch 201/800] [D loss: 0.046017, acc:  97%] [G loss: 7.339518, adv: 0.911698, recon: 0.180292, id: 0.819248] time: 0:20:02.172181 \n","[Epoch 6/1000] [Batch 401/800] [D loss: 0.042764, acc: 100%] [G loss: 5.221641, adv: 0.928855, recon: 0.097823, id: 0.290199] time: 0:20:36.820867 \n","[Epoch 6/1000] [Batch 601/800] [D loss: 0.065369, acc:  93%] [G loss: 5.722161, adv: 0.913901, recon: 0.125218, id: 0.425910] time: 0:21:11.530253 \n","[Epoch 6/1000] [Batch 799/800] [D loss: 0.025834, acc: 100%] [G loss: 6.067295, adv: 0.990086, recon: 0.128631, id: 0.459271] time: 0:21:45.748567 \n","[Epoch 7/1000] [Batch 1/800] [D loss: 0.037427, acc: 100%] [G loss: 5.977872, adv: 0.898647, recon: 0.125116, id: 0.754280] time: 0:21:48.751680 \n","[Epoch 7/1000] [Batch 201/800] [D loss: 0.060456, acc: 100%] [G loss: 5.756078, adv: 1.071585, recon: 0.100062, id: 0.574242] time: 0:22:24.392719 \n","[Epoch 7/1000] [Batch 401/800] [D loss: 0.033471, acc: 100%] [G loss: 5.266751, adv: 0.923479, recon: 0.104152, id: 0.348295] time: 0:22:58.354645 \n","[Epoch 7/1000] [Batch 601/800] [D loss: 0.040576, acc:  98%] [G loss: 6.277060, adv: 0.975255, recon: 0.148781, id: 0.221695] time: 0:23:32.552128 \n","[Epoch 7/1000] [Batch 799/800] [D loss: 0.041803, acc: 100%] [G loss: 5.389293, adv: 0.846689, recon: 0.123186, id: 0.201173] time: 0:24:07.219819 \n","[Epoch 8/1000] [Batch 1/800] [D loss: 0.022431, acc: 100%] [G loss: 5.174435, adv: 0.970898, recon: 0.101821, id: 0.220730] time: 0:24:10.174797 \n","[Epoch 8/1000] [Batch 201/800] [D loss: 0.216425, acc:  65%] [G loss: 5.282942, adv: 0.714269, recon: 0.133149, id: 0.327949] time: 0:24:44.601477 \n","[Epoch 8/1000] [Batch 401/800] [D loss: 0.304946, acc:  68%] [G loss: 4.834908, adv: 0.647424, recon: 0.094832, id: 0.488579] time: 0:25:19.132173 \n","[Epoch 8/1000] [Batch 601/800] [D loss: 0.101209, acc:  85%] [G loss: 6.226403, adv: 1.263129, recon: 0.122463, id: 0.210625] time: 0:25:54.552022 \n","[Epoch 8/1000] [Batch 799/800] [D loss: 0.031591, acc: 100%] [G loss: 5.891303, adv: 1.004138, recon: 0.123150, id: 0.221823] time: 0:26:28.819461 \n","[Epoch 9/1000] [Batch 1/800] [D loss: 0.020773, acc: 100%] [G loss: 7.133574, adv: 1.112892, recon: 0.171823, id: 0.367226] time: 0:26:31.486019 \n","[Epoch 9/1000] [Batch 201/800] [D loss: 0.066720, acc:  98%] [G loss: 7.260970, adv: 0.950229, recon: 0.195502, id: 0.434228] time: 0:27:06.342706 \n","[Epoch 9/1000] [Batch 401/800] [D loss: 0.076830, acc:  92%] [G loss: 6.418526, adv: 1.144378, recon: 0.121926, id: 0.613340] time: 0:27:41.496291 \n","[Epoch 9/1000] [Batch 601/800] [D loss: 0.018781, acc: 100%] [G loss: 5.781538, adv: 1.045152, recon: 0.098932, id: 0.662630] time: 0:28:15.924545 \n","[Epoch 9/1000] [Batch 799/800] [D loss: 0.164222, acc:  75%] [G loss: 5.428128, adv: 0.993247, recon: 0.098762, id: 0.340879] time: 0:28:49.653916 \n","[Epoch 10/1000] [Batch 1/800] [D loss: 0.078052, acc: 100%] [G loss: 5.622297, adv: 1.096575, recon: 0.108401, id: 0.177357] time: 0:28:52.321806 \n","[Epoch 10/1000] [Batch 201/800] [D loss: 0.017155, acc: 100%] [G loss: 6.080339, adv: 1.061276, recon: 0.128427, id: 0.512818] time: 0:29:27.660838 \n","[Epoch 10/1000] [Batch 401/800] [D loss: 0.064802, acc:  97%] [G loss: 5.106073, adv: 0.875392, recon: 0.105523, id: 0.211521] time: 0:30:01.807690 \n","[Epoch 10/1000] [Batch 601/800] [D loss: 0.017667, acc: 100%] [G loss: 4.842620, adv: 0.940379, recon: 0.086682, id: 0.237071] time: 0:30:35.856004 \n","[Epoch 10/1000] [Batch 799/800] [D loss: 0.015306, acc: 100%] [G loss: 5.990912, adv: 1.011813, recon: 0.113872, id: 0.636292] time: 0:31:10.229867 \n","[Epoch 11/1000] [Batch 1/800] [D loss: 0.111784, acc:  77%] [G loss: 6.683365, adv: 1.426467, recon: 0.122648, id: 0.474347] time: 0:31:12.967755 \n","[Epoch 11/1000] [Batch 201/800] [D loss: 0.035399, acc: 100%] [G loss: 5.595272, adv: 0.953318, recon: 0.119554, id: 0.223665] time: 0:31:50.456203 \n","[Epoch 11/1000] [Batch 401/800] [D loss: 0.009713, acc: 100%] [G loss: 5.766234, adv: 1.043244, recon: 0.133072, id: 0.267012] time: 0:32:26.382714 \n","[Epoch 11/1000] [Batch 601/800] [D loss: 0.021677, acc: 100%] [G loss: 6.159120, adv: 1.226575, recon: 0.124965, id: 0.191232] time: 0:33:02.313502 \n","[Epoch 11/1000] [Batch 799/800] [D loss: 0.027873, acc:  99%] [G loss: 6.511868, adv: 0.997876, recon: 0.147180, id: 0.529636] time: 0:33:37.535085 \n","[Epoch 12/1000] [Batch 1/800] [D loss: 0.167568, acc: 100%] [G loss: 6.100139, adv: 1.034093, recon: 0.124850, id: 0.431069] time: 0:33:40.020263 \n","[Epoch 12/1000] [Batch 201/800] [D loss: 0.043365, acc: 100%] [G loss: 5.368611, adv: 1.082492, recon: 0.118464, id: 0.285192] time: 0:34:15.061816 \n","[Epoch 12/1000] [Batch 401/800] [D loss: 0.174065, acc:  69%] [G loss: 4.955039, adv: 0.869750, recon: 0.125262, id: 0.309872] time: 0:34:49.724368 \n","[Epoch 12/1000] [Batch 601/800] [D loss: 0.027741, acc: 100%] [G loss: 5.539418, adv: 0.873994, recon: 0.122385, id: 0.381200] time: 0:35:25.746782 \n","[Epoch 12/1000] [Batch 799/800] [D loss: 0.054877, acc: 100%] [G loss: 5.447013, adv: 1.113936, recon: 0.104546, id: 0.166125] time: 0:36:01.030136 \n","[Epoch 13/1000] [Batch 1/800] [D loss: 0.041261, acc: 100%] [G loss: 5.313445, adv: 0.935286, recon: 0.095402, id: 0.590782] time: 0:36:03.947521 \n","[Epoch 13/1000] [Batch 201/800] [D loss: 0.034347, acc:  99%] [G loss: 5.512887, adv: 0.985904, recon: 0.111053, id: 0.247877] time: 0:36:38.795340 \n","[Epoch 13/1000] [Batch 401/800] [D loss: 0.042271, acc:  99%] [G loss: 5.092170, adv: 0.989294, recon: 0.095049, id: 0.693926] time: 0:37:13.969564 \n","[Epoch 13/1000] [Batch 601/800] [D loss: 0.042343, acc: 100%] [G loss: 5.654591, adv: 1.038161, recon: 0.096716, id: 0.637438] time: 0:37:49.825006 \n","[Epoch 13/1000] [Batch 799/800] [D loss: 0.024489, acc: 100%] [G loss: 5.096071, adv: 0.944706, recon: 0.075373, id: 0.762470] time: 0:38:24.488017 \n","[Epoch 14/1000] [Batch 1/800] [D loss: 0.005893, acc: 100%] [G loss: 7.098661, adv: 1.036553, recon: 0.165728, id: 0.712384] time: 0:38:27.372546 \n","[Epoch 14/1000] [Batch 201/800] [D loss: 0.071890, acc:  99%] [G loss: 9.566657, adv: 0.948716, recon: 0.304041, id: 0.574383] time: 0:39:01.670339 \n","[Epoch 14/1000] [Batch 401/800] [D loss: 0.013577, acc: 100%] [G loss: 5.595537, adv: 1.020661, recon: 0.105629, id: 0.515622] time: 0:39:36.514711 \n","[Epoch 14/1000] [Batch 601/800] [D loss: 0.032331, acc: 100%] [G loss: 7.422551, adv: 1.296469, recon: 0.141310, id: 0.835258] time: 0:40:11.313394 \n","[Epoch 14/1000] [Batch 799/800] [D loss: 0.038248, acc: 100%] [G loss: 4.679995, adv: 1.076899, recon: 0.100389, id: 0.223109] time: 0:40:44.788310 \n","[Epoch 15/1000] [Batch 1/800] [D loss: 0.018918, acc: 100%] [G loss: 4.892737, adv: 1.022874, recon: 0.121451, id: 0.233311] time: 0:40:47.656828 \n","[Epoch 15/1000] [Batch 201/800] [D loss: 0.144504, acc:  75%] [G loss: 4.549770, adv: 0.828834, recon: 0.092641, id: 0.195351] time: 0:41:21.798474 \n","[Epoch 15/1000] [Batch 401/800] [D loss: 0.028798, acc: 100%] [G loss: 4.933738, adv: 0.978435, recon: 0.120408, id: 0.277733] time: 0:41:56.153131 \n","[Epoch 15/1000] [Batch 601/800] [D loss: 0.057540, acc:  99%] [G loss: 5.564801, adv: 0.992121, recon: 0.127451, id: 0.882165] time: 0:42:31.431151 \n","[Epoch 15/1000] [Batch 799/800] [D loss: 0.011704, acc: 100%] [G loss: 5.294241, adv: 1.021532, recon: 0.093350, id: 0.347550] time: 0:43:05.633654 \n","[Epoch 16/1000] [Batch 1/800] [D loss: 0.037059, acc: 100%] [G loss: 5.285405, adv: 0.994457, recon: 0.091014, id: 0.471623] time: 0:43:08.446995 \n","[Epoch 16/1000] [Batch 201/800] [D loss: 0.037790, acc: 100%] [G loss: 4.697858, adv: 1.075669, recon: 0.096281, id: 0.288508] time: 0:43:43.062306 \n","[Epoch 16/1000] [Batch 401/800] [D loss: 0.017157, acc: 100%] [G loss: 5.351235, adv: 1.045897, recon: 0.108369, id: 0.444807] time: 0:44:17.530332 \n","[Epoch 16/1000] [Batch 601/800] [D loss: 0.075909, acc:  88%] [G loss: 4.745621, adv: 0.916600, recon: 0.092040, id: 0.266102] time: 0:44:52.539037 \n","[Epoch 16/1000] [Batch 799/800] [D loss: 0.010390, acc: 100%] [G loss: 5.060852, adv: 1.010970, recon: 0.108485, id: 0.531103] time: 0:45:26.998789 \n","[Epoch 17/1000] [Batch 1/800] [D loss: 0.010349, acc: 100%] [G loss: 4.448946, adv: 1.046954, recon: 0.091315, id: 0.220191] time: 0:45:29.768672 \n","[Epoch 17/1000] [Batch 201/800] [D loss: 0.005070, acc: 100%] [G loss: 5.272140, adv: 0.995710, recon: 0.123619, id: 0.660675] time: 0:46:03.722337 \n","[Epoch 17/1000] [Batch 401/800] [D loss: 0.004489, acc: 100%] [G loss: 5.935112, adv: 0.929570, recon: 0.131971, id: 0.204663] time: 0:46:37.870609 \n","[Epoch 17/1000] [Batch 601/800] [D loss: 0.190968, acc:  64%] [G loss: 5.423224, adv: 1.017770, recon: 0.083944, id: 0.689308] time: 0:47:11.488054 \n","[Epoch 17/1000] [Batch 799/800] [D loss: 0.026089, acc: 100%] [G loss: 5.700831, adv: 1.222830, recon: 0.119818, id: 0.691894] time: 0:47:46.323232 \n","[Epoch 18/1000] [Batch 1/800] [D loss: 0.015891, acc: 100%] [G loss: 5.471813, adv: 0.994904, recon: 0.121739, id: 0.824080] time: 0:47:49.183234 \n","[Epoch 18/1000] [Batch 201/800] [D loss: 0.138399, acc:  79%] [G loss: 3.809450, adv: 0.965488, recon: 0.078158, id: 0.153943] time: 0:48:23.846358 \n","[Epoch 18/1000] [Batch 401/800] [D loss: 0.121375, acc:  77%] [G loss: 4.425571, adv: 0.698191, recon: 0.087891, id: 0.204886] time: 0:48:58.274154 \n","[Epoch 18/1000] [Batch 601/800] [D loss: 0.083207, acc:  90%] [G loss: 5.504737, adv: 0.813220, recon: 0.132760, id: 0.191778] time: 0:49:32.106047 \n","[Epoch 18/1000] [Batch 799/800] [D loss: 0.158909, acc:  69%] [G loss: 5.441137, adv: 0.684251, recon: 0.128322, id: 0.667387] time: 0:50:06.695044 \n","[Epoch 19/1000] [Batch 1/800] [D loss: 0.072297, acc:  95%] [G loss: 4.241739, adv: 0.812347, recon: 0.073088, id: 0.196453] time: 0:50:09.136712 \n","[Epoch 19/1000] [Batch 201/800] [D loss: 0.008562, acc: 100%] [G loss: 4.453044, adv: 1.020465, recon: 0.093568, id: 0.329241] time: 0:50:43.156451 \n","[Epoch 19/1000] [Batch 401/800] [D loss: 0.024186, acc: 100%] [G loss: 5.833805, adv: 1.044661, recon: 0.143317, id: 0.673200] time: 0:51:17.641722 \n","[Epoch 19/1000] [Batch 601/800] [D loss: 0.006390, acc: 100%] [G loss: 5.018957, adv: 0.974470, recon: 0.104399, id: 0.818321] time: 0:51:51.935177 \n","[Epoch 19/1000] [Batch 799/800] [D loss: 0.060263, acc:  98%] [G loss: 14.926040, adv: 1.355006, recon: 0.547663, id: 0.214138] time: 0:52:26.049855 \n","[Epoch 20/1000] [Batch 1/800] [D loss: 0.026771, acc: 100%] [G loss: 5.644252, adv: 1.036820, recon: 0.108159, id: 0.422093] time: 0:52:28.937998 \n","[Epoch 20/1000] [Batch 201/800] [D loss: 0.052430, acc: 100%] [G loss: 5.405065, adv: 1.034526, recon: 0.105179, id: 0.212366] time: 0:53:04.320114 \n","[Epoch 20/1000] [Batch 401/800] [D loss: 0.044488, acc:  99%] [G loss: 5.447229, adv: 0.986619, recon: 0.102733, id: 0.471934] time: 0:53:39.317639 \n","[Epoch 20/1000] [Batch 601/800] [D loss: 0.011334, acc: 100%] [G loss: 5.040257, adv: 1.147146, recon: 0.079114, id: 0.166414] time: 0:54:13.902040 \n","[Epoch 20/1000] [Batch 799/800] [D loss: 0.013080, acc: 100%] [G loss: 5.117777, adv: 1.116985, recon: 0.083229, id: 0.179927] time: 0:54:48.069075 \n","[Epoch 21/1000] [Batch 1/800] [D loss: 0.010420, acc: 100%] [G loss: 6.118351, adv: 0.941934, recon: 0.144756, id: 0.189395] time: 0:54:50.947164 \n","[Epoch 21/1000] [Batch 201/800] [D loss: 0.126892, acc:  72%] [G loss: 13.860351, adv: 0.936266, recon: 0.517563, id: 0.616975] time: 0:55:25.735548 \n","[Epoch 21/1000] [Batch 401/800] [D loss: 0.011501, acc: 100%] [G loss: 5.158571, adv: 0.997421, recon: 0.108899, id: 0.310618] time: 0:56:01.007351 \n","[Epoch 21/1000] [Batch 601/800] [D loss: 0.011461, acc: 100%] [G loss: 5.393457, adv: 1.039950, recon: 0.095773, id: 0.461700] time: 0:56:35.446629 \n","[Epoch 21/1000] [Batch 799/800] [D loss: 0.002183, acc: 100%] [G loss: 4.661469, adv: 1.011957, recon: 0.113632, id: 0.211521] time: 0:57:10.034763 \n","[Epoch 22/1000] [Batch 1/800] [D loss: 0.008134, acc: 100%] [G loss: 4.840103, adv: 1.019059, recon: 0.107324, id: 0.414756] time: 0:57:12.877760 \n","[Epoch 22/1000] [Batch 201/800] [D loss: 0.018802, acc: 100%] [G loss: 11.077711, adv: 1.050846, recon: 0.427242, id: 0.215996] time: 0:57:47.201018 \n","[Epoch 22/1000] [Batch 401/800] [D loss: 0.002623, acc: 100%] [G loss: 5.369972, adv: 0.992034, recon: 0.112014, id: 0.114654] time: 0:58:21.059961 \n","[Epoch 22/1000] [Batch 601/800] [D loss: 0.020832, acc: 100%] [G loss: 5.450891, adv: 1.033668, recon: 0.084728, id: 0.692435] time: 0:58:55.794627 \n","[Epoch 22/1000] [Batch 799/800] [D loss: 0.016429, acc: 100%] [G loss: 7.282603, adv: 1.110402, recon: 0.150611, id: 0.985882] time: 0:59:31.156761 \n","[Epoch 23/1000] [Batch 1/800] [D loss: 0.055056, acc:  99%] [G loss: 6.707447, adv: 1.058214, recon: 0.130270, id: 0.810662] time: 0:59:34.011436 \n","[Epoch 23/1000] [Batch 201/800] [D loss: 0.007151, acc: 100%] [G loss: 5.135775, adv: 0.989503, recon: 0.090925, id: 0.204386] time: 1:00:08.576482 \n","[Epoch 23/1000] [Batch 401/800] [D loss: 0.003946, acc: 100%] [G loss: 5.256724, adv: 0.985679, recon: 0.083229, id: 0.564372] time: 1:00:42.498740 \n","[Epoch 23/1000] [Batch 601/800] [D loss: 0.021048, acc: 100%] [G loss: 6.023032, adv: 1.039129, recon: 0.107118, id: 0.823376] time: 1:01:16.760494 \n","[Epoch 23/1000] [Batch 799/800] [D loss: 0.010883, acc: 100%] [G loss: 5.274070, adv: 0.990731, recon: 0.088482, id: 0.705811] time: 1:01:50.508931 \n","[Epoch 24/1000] [Batch 1/800] [D loss: 0.014385, acc: 100%] [G loss: 6.243213, adv: 1.023617, recon: 0.118149, id: 0.929907] time: 1:01:53.212637 \n","[Epoch 24/1000] [Batch 201/800] [D loss: 0.010282, acc: 100%] [G loss: 5.968612, adv: 0.941139, recon: 0.134983, id: 0.455205] time: 1:02:29.070128 \n","[Epoch 24/1000] [Batch 401/800] [D loss: 0.006558, acc: 100%] [G loss: 4.782349, adv: 0.972238, recon: 0.080100, id: 0.176196] time: 1:03:03.457672 \n","[Epoch 24/1000] [Batch 601/800] [D loss: 0.179838, acc:  80%] [G loss: 5.123734, adv: 0.912314, recon: 0.102186, id: 0.159501] time: 1:03:37.131783 \n","[Epoch 24/1000] [Batch 799/800] [D loss: 0.008421, acc: 100%] [G loss: 4.482677, adv: 0.942243, recon: 0.074908, id: 0.139290] time: 1:04:11.291341 \n","[Epoch 25/1000] [Batch 1/800] [D loss: 0.005191, acc: 100%] [G loss: 5.243661, adv: 1.048255, recon: 0.105235, id: 0.153149] time: 1:04:14.233548 \n","[Epoch 25/1000] [Batch 201/800] [D loss: 0.002931, acc: 100%] [G loss: 5.564302, adv: 1.025350, recon: 0.127828, id: 0.345396] time: 1:04:47.800540 \n","[Epoch 25/1000] [Batch 401/800] [D loss: 0.005422, acc: 100%] [G loss: 4.749031, adv: 0.951938, recon: 0.098092, id: 0.404643] time: 1:05:22.460634 \n","[Epoch 25/1000] [Batch 601/800] [D loss: 0.005079, acc: 100%] [G loss: 3.983297, adv: 0.968799, recon: 0.061388, id: 0.116491] time: 1:05:57.027259 \n","[Epoch 25/1000] [Batch 799/800] [D loss: 0.020151, acc: 100%] [G loss: 4.158719, adv: 0.841517, recon: 0.087187, id: 0.198523] time: 1:06:31.088222 \n","[Epoch 26/1000] [Batch 1/800] [D loss: 0.007226, acc: 100%] [G loss: 5.232981, adv: 0.982505, recon: 0.125742, id: 0.170799] time: 1:06:33.733213 \n","[Epoch 26/1000] [Batch 201/800] [D loss: 0.002225, acc: 100%] [G loss: 4.372463, adv: 1.033999, recon: 0.086522, id: 0.162805] time: 1:07:07.895060 \n","[Epoch 26/1000] [Batch 401/800] [D loss: 0.008392, acc: 100%] [G loss: 5.279154, adv: 1.069433, recon: 0.116145, id: 0.575549] time: 1:07:42.313654 \n","[Epoch 26/1000] [Batch 601/800] [D loss: 0.004663, acc: 100%] [G loss: 4.343141, adv: 1.024813, recon: 0.091924, id: 0.170417] time: 1:08:16.323413 \n","[Epoch 26/1000] [Batch 799/800] [D loss: 0.010365, acc: 100%] [G loss: 4.102682, adv: 0.983244, recon: 0.084792, id: 0.188405] time: 1:08:50.608907 \n","[Epoch 27/1000] [Batch 1/800] [D loss: 0.007517, acc: 100%] [G loss: 4.193251, adv: 0.992122, recon: 0.076762, id: 0.116086] time: 1:08:53.079428 \n","[Epoch 27/1000] [Batch 201/800] [D loss: 0.004710, acc: 100%] [G loss: 4.939218, adv: 1.016963, recon: 0.119165, id: 0.222164] time: 1:09:28.221178 \n","[Epoch 27/1000] [Batch 401/800] [D loss: 0.004462, acc: 100%] [G loss: 3.913646, adv: 0.925508, recon: 0.083257, id: 0.186917] time: 1:10:02.054314 \n","[Epoch 27/1000] [Batch 601/800] [D loss: 0.048000, acc: 100%] [G loss: 4.070304, adv: 0.962731, recon: 0.087621, id: 0.141675] time: 1:10:35.709231 \n","[Epoch 27/1000] [Batch 799/800] [D loss: 0.008449, acc: 100%] [G loss: 5.902441, adv: 0.950343, recon: 0.120058, id: 0.826806] time: 1:11:09.541487 \n","[Epoch 28/1000] [Batch 1/800] [D loss: 0.005938, acc: 100%] [G loss: 4.576232, adv: 1.026720, recon: 0.082796, id: 0.185115] time: 1:11:12.277092 \n","[Epoch 28/1000] [Batch 201/800] [D loss: 0.012719, acc: 100%] [G loss: 5.948915, adv: 0.990579, recon: 0.153042, id: 0.573447] time: 1:11:46.124153 \n","[Epoch 28/1000] [Batch 401/800] [D loss: 0.003480, acc: 100%] [G loss: 4.566813, adv: 0.999870, recon: 0.079705, id: 0.144872] time: 1:12:20.937059 \n","[Epoch 28/1000] [Batch 601/800] [D loss: 0.009140, acc: 100%] [G loss: 5.334902, adv: 0.966954, recon: 0.133051, id: 0.269112] time: 1:12:54.470091 \n","[Epoch 28/1000] [Batch 799/800] [D loss: 0.004440, acc: 100%] [G loss: 4.820654, adv: 1.001022, recon: 0.084101, id: 0.766715] time: 1:13:29.154820 \n","[Epoch 29/1000] [Batch 1/800] [D loss: 0.001885, acc: 100%] [G loss: 4.332870, adv: 1.001788, recon: 0.081635, id: 0.203201] time: 1:13:31.585865 \n","[Epoch 29/1000] [Batch 201/800] [D loss: 0.001846, acc: 100%] [G loss: 4.923771, adv: 1.020105, recon: 0.099667, id: 0.703031] time: 1:14:05.578604 \n","[Epoch 29/1000] [Batch 401/800] [D loss: 0.002821, acc: 100%] [G loss: 4.185285, adv: 1.035100, recon: 0.089380, id: 0.151082] time: 1:14:38.923843 \n","[Epoch 29/1000] [Batch 601/800] [D loss: 0.116330, acc:  82%] [G loss: 5.290878, adv: 0.974583, recon: 0.097705, id: 0.807551] time: 1:15:13.221310 \n","[Epoch 29/1000] [Batch 799/800] [D loss: 0.004262, acc: 100%] [G loss: 4.749745, adv: 1.044046, recon: 0.113843, id: 0.164682] time: 1:15:46.642469 \n","[Epoch 30/1000] [Batch 1/800] [D loss: 0.006519, acc: 100%] [G loss: 3.647943, adv: 0.990782, recon: 0.064618, id: 0.172452] time: 1:15:49.342101 \n","[Epoch 30/1000] [Batch 201/800] [D loss: 0.011106, acc: 100%] [G loss: 4.590299, adv: 0.989914, recon: 0.109119, id: 0.264727] time: 1:16:22.685521 \n","[Epoch 30/1000] [Batch 401/800] [D loss: 0.003030, acc: 100%] [G loss: 5.262315, adv: 0.961555, recon: 0.127807, id: 0.592758] time: 1:16:57.241910 \n","[Epoch 30/1000] [Batch 601/800] [D loss: 0.003619, acc: 100%] [G loss: 3.604445, adv: 1.020263, recon: 0.060227, id: 0.199546] time: 1:17:31.007711 \n","[Epoch 30/1000] [Batch 799/800] [D loss: 0.004302, acc: 100%] [G loss: 5.921701, adv: 1.040084, recon: 0.163517, id: 0.394297] time: 1:18:04.951732 \n","[Epoch 31/1000] [Batch 1/800] [D loss: 0.007737, acc: 100%] [G loss: 5.449053, adv: 0.983696, recon: 0.154048, id: 0.241052] time: 1:18:07.390026 \n","[Epoch 31/1000] [Batch 201/800] [D loss: 0.001168, acc: 100%] [G loss: 4.183132, adv: 0.995153, recon: 0.084772, id: 0.334558] time: 1:18:41.754731 \n","[Epoch 31/1000] [Batch 401/800] [D loss: 0.007782, acc: 100%] [G loss: 4.254949, adv: 1.027334, recon: 0.090916, id: 0.184876] time: 1:19:16.040503 \n","[Epoch 31/1000] [Batch 601/800] [D loss: 0.004845, acc: 100%] [G loss: 4.211454, adv: 1.026324, recon: 0.065744, id: 0.676132] time: 1:19:50.671512 \n","[Epoch 31/1000] [Batch 799/800] [D loss: 0.049137, acc:  96%] [G loss: 4.225155, adv: 1.194809, recon: 0.076623, id: 0.155706] time: 1:20:24.688166 \n","[Epoch 32/1000] [Batch 1/800] [D loss: 0.118511, acc:  75%] [G loss: 4.078261, adv: 0.917801, recon: 0.093667, id: 0.164681] time: 1:20:27.654653 \n","[Epoch 32/1000] [Batch 201/800] [D loss: 0.006370, acc: 100%] [G loss: 4.014310, adv: 1.002552, recon: 0.080926, id: 0.129111] time: 1:21:03.550596 \n","[Epoch 32/1000] [Batch 401/800] [D loss: 0.009587, acc: 100%] [G loss: 4.409961, adv: 0.987431, recon: 0.085588, id: 0.153354] time: 1:21:37.421674 \n","[Epoch 32/1000] [Batch 601/800] [D loss: 0.001550, acc: 100%] [G loss: 5.258420, adv: 0.982077, recon: 0.115792, id: 0.603544] time: 1:22:11.828085 \n","[Epoch 32/1000] [Batch 799/800] [D loss: 0.001543, acc: 100%] [G loss: 5.094850, adv: 1.024102, recon: 0.080570, id: 0.622587] time: 1:22:45.895396 \n","[Epoch 33/1000] [Batch 1/800] [D loss: 0.002044, acc: 100%] [G loss: 5.127135, adv: 0.970702, recon: 0.090530, id: 0.673415] time: 1:22:48.552604 \n","[Epoch 33/1000] [Batch 201/800] [D loss: 0.001076, acc: 100%] [G loss: 3.823859, adv: 0.973863, recon: 0.074990, id: 0.156410] time: 1:23:23.106132 \n","[Epoch 33/1000] [Batch 401/800] [D loss: 0.072793, acc:  87%] [G loss: 4.105373, adv: 1.162471, recon: 0.063529, id: 0.254181] time: 1:23:57.582968 \n","[Epoch 33/1000] [Batch 601/800] [D loss: 0.012910, acc: 100%] [G loss: 5.799301, adv: 0.930705, recon: 0.116457, id: 0.875177] time: 1:24:31.938119 \n","[Epoch 33/1000] [Batch 799/800] [D loss: 0.008047, acc: 100%] [G loss: 3.556476, adv: 0.975385, recon: 0.059669, id: 0.130552] time: 1:25:05.738484 \n","[Epoch 34/1000] [Batch 1/800] [D loss: 0.001893, acc: 100%] [G loss: 3.892671, adv: 1.043134, recon: 0.073479, id: 0.158628] time: 1:25:09.768239 \n","[Epoch 34/1000] [Batch 201/800] [D loss: 0.001590, acc: 100%] [G loss: 4.088335, adv: 0.996664, recon: 0.082282, id: 0.270389] time: 1:25:43.603935 \n","[Epoch 34/1000] [Batch 401/800] [D loss: 0.009305, acc: 100%] [G loss: 3.659407, adv: 0.980382, recon: 0.071686, id: 0.151572] time: 1:26:18.125396 \n","[Epoch 34/1000] [Batch 601/800] [D loss: 0.136384, acc:  76%] [G loss: 5.062436, adv: 1.098671, recon: 0.095679, id: 0.218503] time: 1:26:52.713898 \n","[Epoch 34/1000] [Batch 799/800] [D loss: 0.003117, acc: 100%] [G loss: 4.043916, adv: 1.000346, recon: 0.078857, id: 0.262823] time: 1:27:26.776962 \n","[Epoch 35/1000] [Batch 1/800] [D loss: 0.001594, acc: 100%] [G loss: 4.645687, adv: 1.029292, recon: 0.104937, id: 0.310187] time: 1:27:29.482660 \n","[Epoch 35/1000] [Batch 201/800] [D loss: 0.003011, acc: 100%] [G loss: 4.314059, adv: 1.010370, recon: 0.092897, id: 0.277543] time: 1:28:04.443824 \n","[Epoch 35/1000] [Batch 401/800] [D loss: 0.001942, acc: 100%] [G loss: 5.718337, adv: 1.005503, recon: 0.120401, id: 0.209059] time: 1:28:38.533849 \n","[Epoch 35/1000] [Batch 601/800] [D loss: 0.000848, acc: 100%] [G loss: 3.601557, adv: 0.982155, recon: 0.066794, id: 0.163570] time: 1:29:12.552086 \n","[Epoch 35/1000] [Batch 799/800] [D loss: 0.005477, acc: 100%] [G loss: 3.960653, adv: 1.064260, recon: 0.054335, id: 0.635358] time: 1:29:48.205083 \n","[Epoch 36/1000] [Batch 1/800] [D loss: 0.003472, acc: 100%] [G loss: 3.820192, adv: 1.025374, recon: 0.072100, id: 0.184689] time: 1:29:50.919350 \n","[Epoch 36/1000] [Batch 201/800] [D loss: 0.001945, acc: 100%] [G loss: 3.578489, adv: 1.000621, recon: 0.063535, id: 0.159605] time: 1:30:25.455073 \n","[Epoch 36/1000] [Batch 401/800] [D loss: 0.010943, acc: 100%] [G loss: 4.767401, adv: 0.989991, recon: 0.118710, id: 0.285245] time: 1:30:59.728761 \n","[Epoch 36/1000] [Batch 601/800] [D loss: 0.013673, acc: 100%] [G loss: 4.719328, adv: 1.103196, recon: 0.082432, id: 0.182401] time: 1:31:34.138893 \n","[Epoch 36/1000] [Batch 799/800] [D loss: 0.003602, acc: 100%] [G loss: 4.486769, adv: 1.018070, recon: 0.088754, id: 0.491452] time: 1:32:08.143023 \n","[Epoch 37/1000] [Batch 1/800] [D loss: 0.001740, acc: 100%] [G loss: 5.500892, adv: 1.033261, recon: 0.111237, id: 0.397137] time: 1:32:11.046212 \n","[Epoch 37/1000] [Batch 201/800] [D loss: 0.003177, acc: 100%] [G loss: 4.418847, adv: 1.031231, recon: 0.086207, id: 0.492026] time: 1:32:45.586115 \n","[Epoch 37/1000] [Batch 401/800] [D loss: 0.001935, acc: 100%] [G loss: 3.545205, adv: 1.040387, recon: 0.060531, id: 0.097300] time: 1:33:19.567274 \n","[Epoch 37/1000] [Batch 601/800] [D loss: 0.009358, acc: 100%] [G loss: 4.928296, adv: 0.961578, recon: 0.085677, id: 0.207111] time: 1:33:53.769295 \n","[Epoch 37/1000] [Batch 799/800] [D loss: 0.001699, acc: 100%] [G loss: 3.785221, adv: 0.988419, recon: 0.072726, id: 0.164376] time: 1:34:29.246627 \n","[Epoch 38/1000] [Batch 1/800] [D loss: 0.005649, acc: 100%] [G loss: 3.868614, adv: 0.968839, recon: 0.078023, id: 0.188294] time: 1:34:32.088553 \n","[Epoch 38/1000] [Batch 201/800] [D loss: 0.002237, acc: 100%] [G loss: 3.829983, adv: 1.017269, recon: 0.073973, id: 0.199415] time: 1:35:06.929905 \n","[Epoch 38/1000] [Batch 401/800] [D loss: 0.001613, acc: 100%] [G loss: 4.096056, adv: 0.978710, recon: 0.091172, id: 0.171350] time: 1:35:40.916556 \n","[Epoch 38/1000] [Batch 601/800] [D loss: 0.005107, acc: 100%] [G loss: 3.495369, adv: 0.981067, recon: 0.061973, id: 0.153414] time: 1:36:15.097747 \n","[Epoch 38/1000] [Batch 799/800] [D loss: 0.001211, acc: 100%] [G loss: 4.419084, adv: 0.997847, recon: 0.092970, id: 0.278622] time: 1:36:48.814154 \n","[Epoch 39/1000] [Batch 1/800] [D loss: 0.001276, acc: 100%] [G loss: 3.810967, adv: 0.975407, recon: 0.069269, id: 0.317635] time: 1:36:51.388462 \n","[Epoch 39/1000] [Batch 201/800] [D loss: 0.000363, acc: 100%] [G loss: 3.699337, adv: 0.994876, recon: 0.067797, id: 0.168812] time: 1:37:25.056552 \n","[Epoch 39/1000] [Batch 401/800] [D loss: 0.211364, acc:  66%] [G loss: 2.965334, adv: 0.704546, recon: 0.062207, id: 0.117364] time: 1:37:59.292639 \n","[Epoch 39/1000] [Batch 601/800] [D loss: 0.002381, acc: 100%] [G loss: 3.424141, adv: 0.989726, recon: 0.049796, id: 0.281730] time: 1:38:33.963300 \n","[Epoch 39/1000] [Batch 799/800] [D loss: 0.009830, acc: 100%] [G loss: 4.040322, adv: 1.042967, recon: 0.077957, id: 0.271619] time: 1:39:09.011046 \n","[Epoch 40/1000] [Batch 1/800] [D loss: 0.004965, acc: 100%] [G loss: 4.023315, adv: 1.057521, recon: 0.077858, id: 0.228882] time: 1:39:11.903387 \n","[Epoch 40/1000] [Batch 201/800] [D loss: 0.002763, acc: 100%] [G loss: 3.890571, adv: 0.961963, recon: 0.075757, id: 0.281253] time: 1:39:46.259538 \n","[Epoch 40/1000] [Batch 401/800] [D loss: 0.012458, acc: 100%] [G loss: 3.918178, adv: 1.035519, recon: 0.071774, id: 0.268965] time: 1:40:20.812769 \n","[Epoch 40/1000] [Batch 601/800] [D loss: 0.000964, acc: 100%] [G loss: 4.504534, adv: 1.004391, recon: 0.088334, id: 0.536430] time: 1:40:54.945146 \n","[Epoch 40/1000] [Batch 799/800] [D loss: 0.004627, acc: 100%] [G loss: 3.829860, adv: 1.026488, recon: 0.070281, id: 0.148098] time: 1:41:29.217128 \n","[Epoch 41/1000] [Batch 1/800] [D loss: 0.001043, acc: 100%] [G loss: 3.485241, adv: 1.000427, recon: 0.059398, id: 0.148311] time: 1:41:31.662764 \n","[Epoch 41/1000] [Batch 201/800] [D loss: 0.002093, acc: 100%] [G loss: 3.405277, adv: 0.988837, recon: 0.058735, id: 0.144772] time: 1:42:06.640872 \n","[Epoch 41/1000] [Batch 401/800] [D loss: 0.010734, acc: 100%] [G loss: 3.888288, adv: 1.081984, recon: 0.069950, id: 0.184894] time: 1:42:41.305247 \n","[Epoch 41/1000] [Batch 601/800] [D loss: 0.001284, acc: 100%] [G loss: 4.769986, adv: 1.019910, recon: 0.089906, id: 0.424316] time: 1:43:15.360883 \n","[Epoch 41/1000] [Batch 799/800] [D loss: 0.000713, acc: 100%] [G loss: 4.456482, adv: 1.000001, recon: 0.097805, id: 0.285741] time: 1:43:49.786927 \n","[Epoch 42/1000] [Batch 1/800] [D loss: 0.000631, acc: 100%] [G loss: 4.072353, adv: 1.010361, recon: 0.072818, id: 0.316407] time: 1:43:52.462778 \n","[Epoch 42/1000] [Batch 201/800] [D loss: 0.001204, acc: 100%] [G loss: 3.799242, adv: 0.981547, recon: 0.071920, id: 0.220268] time: 1:44:28.842089 \n","[Epoch 42/1000] [Batch 401/800] [D loss: 0.002799, acc: 100%] [G loss: 3.408572, adv: 0.988189, recon: 0.058483, id: 0.139673] time: 1:45:03.479036 \n","[Epoch 42/1000] [Batch 601/800] [D loss: 0.002263, acc: 100%] [G loss: 3.663362, adv: 1.005336, recon: 0.068125, id: 0.144710] time: 1:45:37.870596 \n","[Epoch 42/1000] [Batch 799/800] [D loss: 0.000790, acc: 100%] [G loss: 4.259196, adv: 0.998687, recon: 0.072108, id: 0.493348] time: 1:46:11.643950 \n","[Epoch 43/1000] [Batch 1/800] [D loss: 0.000966, acc: 100%] [G loss: 4.555423, adv: 1.038688, recon: 0.093484, id: 0.378200] time: 1:46:14.121656 \n","[Epoch 43/1000] [Batch 201/800] [D loss: 0.001471, acc: 100%] [G loss: 3.790661, adv: 0.975417, recon: 0.065912, id: 0.340172] time: 1:46:48.210440 \n","[Epoch 43/1000] [Batch 401/800] [D loss: 0.000776, acc: 100%] [G loss: 4.837063, adv: 0.976661, recon: 0.085056, id: 0.695177] time: 1:47:22.193038 \n","[Epoch 43/1000] [Batch 601/800] [D loss: 0.003841, acc: 100%] [G loss: 5.124179, adv: 1.047246, recon: 0.105619, id: 0.415290] time: 1:47:56.542712 \n","[Epoch 43/1000] [Batch 799/800] [D loss: 0.000879, acc: 100%] [G loss: 3.772347, adv: 0.973672, recon: 0.075731, id: 0.138157] time: 1:48:29.868062 \n","[Epoch 44/1000] [Batch 1/800] [D loss: 0.000808, acc: 100%] [G loss: 3.360170, adv: 1.014556, recon: 0.054319, id: 0.143081] time: 1:48:32.527402 \n","[Epoch 44/1000] [Batch 201/800] [D loss: 0.000968, acc: 100%] [G loss: 3.489604, adv: 0.995133, recon: 0.059097, id: 0.176860] time: 1:49:06.748346 \n","[Epoch 44/1000] [Batch 401/800] [D loss: 0.003607, acc: 100%] [G loss: 3.471964, adv: 0.994626, recon: 0.061603, id: 0.152650] time: 1:49:42.093044 \n","[Epoch 44/1000] [Batch 601/800] [D loss: 0.001072, acc: 100%] [G loss: 4.305093, adv: 1.003715, recon: 0.079523, id: 0.579749] time: 1:50:16.135369 \n","[Epoch 44/1000] [Batch 799/800] [D loss: 0.000616, acc: 100%] [G loss: 3.748590, adv: 1.010539, recon: 0.070629, id: 0.161117] time: 1:50:49.372907 \n","[Epoch 45/1000] [Batch 1/800] [D loss: 0.001402, acc: 100%] [G loss: 3.639099, adv: 1.002031, recon: 0.069514, id: 0.115063] time: 1:50:51.838173 \n","[Epoch 45/1000] [Batch 201/800] [D loss: 0.000340, acc: 100%] [G loss: 3.901812, adv: 0.992718, recon: 0.057253, id: 0.372339] time: 1:51:25.664928 \n","[Epoch 45/1000] [Batch 401/800] [D loss: 0.001201, acc: 100%] [G loss: 3.597530, adv: 0.985238, recon: 0.065442, id: 0.204002] time: 1:52:00.141941 \n","[Epoch 45/1000] [Batch 601/800] [D loss: 0.000772, acc: 100%] [G loss: 3.446752, adv: 0.991766, recon: 0.057782, id: 0.203356] time: 1:52:33.752416 \n","[Epoch 45/1000] [Batch 799/800] [D loss: 0.005104, acc: 100%] [G loss: 3.678894, adv: 0.990713, recon: 0.071469, id: 0.131550] time: 1:53:07.368291 \n","[Epoch 46/1000] [Batch 1/800] [D loss: 0.003508, acc: 100%] [G loss: 4.303924, adv: 1.066286, recon: 0.094197, id: 0.132233] time: 1:53:10.139010 \n","[Epoch 46/1000] [Batch 201/800] [D loss: 0.010331, acc: 100%] [G loss: 4.050219, adv: 1.038217, recon: 0.081454, id: 0.208468] time: 1:53:44.119262 \n","[Epoch 46/1000] [Batch 401/800] [D loss: 0.000416, acc: 100%] [G loss: 3.398698, adv: 1.001788, recon: 0.055055, id: 0.150954] time: 1:54:17.898739 \n","[Epoch 46/1000] [Batch 601/800] [D loss: 0.008283, acc: 100%] [G loss: 4.125700, adv: 1.092970, recon: 0.082356, id: 0.188814] time: 1:54:52.039439 \n","[Epoch 46/1000] [Batch 799/800] [D loss: 0.000990, acc: 100%] [G loss: 3.240060, adv: 0.983826, recon: 0.054481, id: 0.080050] time: 1:55:27.737633 \n","[Epoch 47/1000] [Batch 1/800] [D loss: 0.002706, acc: 100%] [G loss: 3.493388, adv: 1.040330, recon: 0.056924, id: 0.146356] time: 1:55:30.701525 \n","[Epoch 47/1000] [Batch 201/800] [D loss: 0.000676, acc: 100%] [G loss: 3.649465, adv: 1.005093, recon: 0.069458, id: 0.136130] time: 1:56:04.431571 \n","[Epoch 47/1000] [Batch 401/800] [D loss: 0.002082, acc: 100%] [G loss: 3.861440, adv: 1.021294, recon: 0.068572, id: 0.156421] time: 1:56:38.900567 \n","[Epoch 47/1000] [Batch 601/800] [D loss: 0.001704, acc: 100%] [G loss: 3.648939, adv: 0.975530, recon: 0.063242, id: 0.250036] time: 1:57:12.624008 \n","[Epoch 47/1000] [Batch 799/800] [D loss: 0.024034, acc: 100%] [G loss: 3.579521, adv: 0.967562, recon: 0.071084, id: 0.094152] time: 1:57:46.876600 \n","[Epoch 48/1000] [Batch 1/800] [D loss: 0.006580, acc: 100%] [G loss: 3.726331, adv: 1.009034, recon: 0.056053, id: 0.399043] time: 1:57:49.568911 \n","[Epoch 48/1000] [Batch 201/800] [D loss: 0.000674, acc: 100%] [G loss: 3.971837, adv: 0.982745, recon: 0.069620, id: 0.470469] time: 1:58:23.248154 \n","[Epoch 48/1000] [Batch 401/800] [D loss: 0.001102, acc: 100%] [G loss: 3.562302, adv: 0.997067, recon: 0.065093, id: 0.173173] time: 1:58:57.310287 \n","[Epoch 48/1000] [Batch 601/800] [D loss: 0.000610, acc: 100%] [G loss: 4.467424, adv: 1.007108, recon: 0.086112, id: 0.589504] time: 1:59:31.448843 \n","[Epoch 48/1000] [Batch 799/800] [D loss: 0.001160, acc: 100%] [G loss: 3.814888, adv: 1.004777, recon: 0.067429, id: 0.335920] time: 2:00:05.698842 \n","[Epoch 49/1000] [Batch 1/800] [D loss: 0.000664, acc: 100%] [G loss: 3.783812, adv: 0.987932, recon: 0.055571, id: 0.208280] time: 2:00:08.179566 \n","[Epoch 49/1000] [Batch 201/800] [D loss: 0.000904, acc: 100%] [G loss: 3.841813, adv: 1.031588, recon: 0.069141, id: 0.259707] time: 2:00:42.637054 \n","[Epoch 49/1000] [Batch 401/800] [D loss: 0.003535, acc: 100%] [G loss: 3.143492, adv: 0.974782, recon: 0.048525, id: 0.105743] time: 2:01:18.938059 \n","[Epoch 49/1000] [Batch 601/800] [D loss: 0.002064, acc: 100%] [G loss: 3.849269, adv: 1.018283, recon: 0.073289, id: 0.235848] time: 2:01:52.789859 \n","[Epoch 49/1000] [Batch 799/800] [D loss: 0.015263, acc: 100%] [G loss: 3.659115, adv: 0.910582, recon: 0.079362, id: 0.138775] time: 2:02:26.332467 \n","[Epoch 50/1000] [Batch 1/800] [D loss: 0.042787, acc:  96%] [G loss: 3.609398, adv: 0.971072, recon: 0.050709, id: 0.532843] time: 2:02:29.057630 \n","[Epoch 50/1000] [Batch 201/800] [D loss: 0.000577, acc: 100%] [G loss: 3.624575, adv: 0.979119, recon: 0.057545, id: 0.409637] time: 2:03:03.956830 \n","[Epoch 50/1000] [Batch 401/800] [D loss: 0.000455, acc: 100%] [G loss: 3.672914, adv: 1.011750, recon: 0.057898, id: 0.365875] time: 2:03:38.657500 \n","[Epoch 50/1000] [Batch 601/800] [D loss: 0.000830, acc: 100%] [G loss: 4.009362, adv: 0.978413, recon: 0.069705, id: 0.466750] time: 2:04:13.231606 \n","[Epoch 50/1000] [Batch 799/800] [D loss: 0.000696, acc: 100%] [G loss: 3.650394, adv: 1.019896, recon: 0.053164, id: 0.419518] time: 2:04:47.780800 \n","[Epoch 51/1000] [Batch 1/800] [D loss: 0.000661, acc: 100%] [G loss: 3.590791, adv: 0.999357, recon: 0.064816, id: 0.197815] time: 2:04:50.356950 \n","[Epoch 51/1000] [Batch 201/800] [D loss: 0.001590, acc: 100%] [G loss: 4.109151, adv: 1.034799, recon: 0.079728, id: 0.196898] time: 2:05:25.815214 \n","[Epoch 51/1000] [Batch 401/800] [D loss: 0.002470, acc: 100%] [G loss: 3.205072, adv: 0.996781, recon: 0.048163, id: 0.113473] time: 2:06:01.137274 \n","[Epoch 51/1000] [Batch 601/800] [D loss: 0.000688, acc: 100%] [G loss: 3.260146, adv: 1.004580, recon: 0.041798, id: 0.076067] time: 2:06:35.763074 \n","[Epoch 51/1000] [Batch 799/800] [D loss: 0.003235, acc: 100%] [G loss: 3.244286, adv: 0.995381, recon: 0.050115, id: 0.135687] time: 2:07:12.960768 \n","[Epoch 52/1000] [Batch 1/800] [D loss: 0.002098, acc: 100%] [G loss: 3.573549, adv: 0.983077, recon: 0.062622, id: 0.227252] time: 2:07:15.540062 \n","[Epoch 52/1000] [Batch 201/800] [D loss: 0.174651, acc:  69%] [G loss: 3.691623, adv: 0.715270, recon: 0.077394, id: 0.550025] time: 2:07:50.508841 \n","[Epoch 52/1000] [Batch 401/800] [D loss: 0.009986, acc: 100%] [G loss: 3.338811, adv: 0.869461, recon: 0.057829, id: 0.289464] time: 2:08:25.711263 \n","[Epoch 52/1000] [Batch 601/800] [D loss: 0.005561, acc: 100%] [G loss: 3.389285, adv: 1.077060, recon: 0.050068, id: 0.131831] time: 2:09:00.976170 \n","[Epoch 52/1000] [Batch 799/800] [D loss: 0.000360, acc: 100%] [G loss: 3.476343, adv: 0.990242, recon: 0.062004, id: 0.153981] time: 2:09:35.497309 \n","[Epoch 53/1000] [Batch 1/800] [D loss: 0.001861, acc: 100%] [G loss: 3.568219, adv: 0.955021, recon: 0.056442, id: 0.414248] time: 2:09:38.221874 \n","[Epoch 53/1000] [Batch 201/800] [D loss: 0.000328, acc: 100%] [G loss: 3.197277, adv: 1.008611, recon: 0.048761, id: 0.104300] time: 2:10:12.848562 \n","[Epoch 53/1000] [Batch 401/800] [D loss: 0.000532, acc: 100%] [G loss: 3.258916, adv: 0.983102, recon: 0.052810, id: 0.098519] time: 2:10:47.466601 \n","[Epoch 53/1000] [Batch 601/800] [D loss: 0.001054, acc: 100%] [G loss: 3.200398, adv: 1.026851, recon: 0.040138, id: 0.111189] time: 2:11:22.756691 \n","[Epoch 53/1000] [Batch 799/800] [D loss: 0.005217, acc: 100%] [G loss: 3.925218, adv: 0.965309, recon: 0.073515, id: 0.143302] time: 2:11:56.559285 \n","[Epoch 54/1000] [Batch 1/800] [D loss: 0.025925, acc:  98%] [G loss: 3.698976, adv: 0.961781, recon: 0.062980, id: 0.177482] time: 2:11:59.578785 \n","[Epoch 54/1000] [Batch 201/800] [D loss: 0.175292, acc:  75%] [G loss: 8.803177, adv: 1.283778, recon: 0.271785, id: 0.282890] time: 2:12:33.981138 \n","[Epoch 54/1000] [Batch 401/800] [D loss: 0.000550, acc: 100%] [G loss: 3.897379, adv: 0.988855, recon: 0.071220, id: 0.393590] time: 2:13:08.610640 \n","[Epoch 54/1000] [Batch 601/800] [D loss: 0.001968, acc: 100%] [G loss: 3.956351, adv: 1.050773, recon: 0.055515, id: 0.415325] time: 2:13:45.375040 \n","[Epoch 54/1000] [Batch 799/800] [D loss: 0.002707, acc: 100%] [G loss: 4.063799, adv: 0.991143, recon: 0.074308, id: 0.464210] time: 2:14:19.320004 \n","[Epoch 55/1000] [Batch 1/800] [D loss: 0.000766, acc: 100%] [G loss: 3.672218, adv: 0.993567, recon: 0.058091, id: 0.424360] time: 2:14:22.027474 \n","[Epoch 55/1000] [Batch 201/800] [D loss: 0.000656, acc: 100%] [G loss: 3.256087, adv: 0.983881, recon: 0.052140, id: 0.190351] time: 2:14:55.562745 \n","[Epoch 55/1000] [Batch 401/800] [D loss: 0.000878, acc: 100%] [G loss: 3.813807, adv: 1.006104, recon: 0.064644, id: 0.325602] time: 2:15:29.911844 \n","[Epoch 55/1000] [Batch 601/800] [D loss: 0.008648, acc: 100%] [G loss: 3.158973, adv: 0.988421, recon: 0.048286, id: 0.122376] time: 2:16:04.434869 \n","[Epoch 55/1000] [Batch 799/800] [D loss: 0.015598, acc: 100%] [G loss: 4.390271, adv: 1.092946, recon: 0.085241, id: 0.125124] time: 2:16:38.563064 \n","[Epoch 56/1000] [Batch 1/800] [D loss: 0.009684, acc: 100%] [G loss: 3.460246, adv: 1.018849, recon: 0.052810, id: 0.151209] time: 2:16:41.251997 \n","[Epoch 56/1000] [Batch 201/800] [D loss: 0.000430, acc: 100%] [G loss: 3.562301, adv: 1.010916, recon: 0.054706, id: 0.132688] time: 2:17:15.411704 \n","[Epoch 56/1000] [Batch 401/800] [D loss: 0.001103, acc: 100%] [G loss: 3.067331, adv: 0.987173, recon: 0.044857, id: 0.088322] time: 2:17:49.332928 \n","[Epoch 56/1000] [Batch 601/800] [D loss: 0.000524, acc: 100%] [G loss: 3.352602, adv: 0.991672, recon: 0.056258, id: 0.126747] time: 2:18:23.255811 \n","[Epoch 56/1000] [Batch 799/800] [D loss: 0.093231, acc:  85%] [G loss: 3.998481, adv: 1.072783, recon: 0.058534, id: 0.512946] time: 2:18:57.224488 \n","[Epoch 57/1000] [Batch 1/800] [D loss: 0.010098, acc: 100%] [G loss: 3.994663, adv: 1.008934, recon: 0.074443, id: 0.338752] time: 2:18:59.737548 \n","[Epoch 57/1000] [Batch 201/800] [D loss: 0.000699, acc: 100%] [G loss: 3.676887, adv: 1.006412, recon: 0.069420, id: 0.167812] time: 2:19:33.897973 \n","[Epoch 57/1000] [Batch 401/800] [D loss: 0.000577, acc: 100%] [G loss: 3.450512, adv: 0.979800, recon: 0.052386, id: 0.140500] time: 2:20:10.334845 \n","[Epoch 57/1000] [Batch 601/800] [D loss: 0.000730, acc: 100%] [G loss: 3.076596, adv: 0.988253, recon: 0.043626, id: 0.123279] time: 2:20:44.960409 \n","[Epoch 57/1000] [Batch 799/800] [D loss: 0.000382, acc: 100%] [G loss: 3.680377, adv: 0.992696, recon: 0.056481, id: 0.337056] time: 2:21:18.695501 \n","[Epoch 58/1000] [Batch 1/800] [D loss: 0.000280, acc: 100%] [G loss: 3.301304, adv: 0.990466, recon: 0.040679, id: 0.351606] time: 2:21:21.499710 \n","[Epoch 58/1000] [Batch 201/800] [D loss: 0.001199, acc: 100%] [G loss: 3.288833, adv: 0.981341, recon: 0.053693, id: 0.163769] time: 2:21:55.560289 \n","[Epoch 58/1000] [Batch 401/800] [D loss: 0.000514, acc: 100%] [G loss: 2.994938, adv: 0.985313, recon: 0.040591, id: 0.120604] time: 2:22:29.490246 \n","[Epoch 58/1000] [Batch 601/800] [D loss: 0.007170, acc: 100%] [G loss: 3.446642, adv: 0.986066, recon: 0.056541, id: 0.226558] time: 2:23:03.734172 \n","[Epoch 58/1000] [Batch 799/800] [D loss: 0.011258, acc: 100%] [G loss: 3.854470, adv: 1.153673, recon: 0.064287, id: 0.113068] time: 2:23:37.382900 \n","[Epoch 59/1000] [Batch 1/800] [D loss: 0.043305, acc:  98%] [G loss: 3.304282, adv: 0.997242, recon: 0.053653, id: 0.126070] time: 2:23:39.845377 \n","[Epoch 59/1000] [Batch 201/800] [D loss: 0.000420, acc: 100%] [G loss: 3.016395, adv: 0.994449, recon: 0.039557, id: 0.083947] time: 2:24:13.785613 \n","[Epoch 59/1000] [Batch 401/800] [D loss: 0.000442, acc: 100%] [G loss: 3.600672, adv: 0.980062, recon: 0.070769, id: 0.118606] time: 2:24:47.471666 \n","[Epoch 59/1000] [Batch 601/800] [D loss: 0.000563, acc: 100%] [G loss: 4.010026, adv: 0.995151, recon: 0.073545, id: 0.444622] time: 2:25:21.372818 \n","[Epoch 59/1000] [Batch 799/800] [D loss: 0.005828, acc: 100%] [G loss: 3.927963, adv: 1.008883, recon: 0.078971, id: 0.170120] time: 2:25:54.826849 \n","[Epoch 60/1000] [Batch 1/800] [D loss: 0.003412, acc: 100%] [G loss: 3.553187, adv: 1.000637, recon: 0.064789, id: 0.176920] time: 2:25:57.373757 \n","[Epoch 60/1000] [Batch 201/800] [D loss: 0.000983, acc: 100%] [G loss: 2.933051, adv: 0.972478, recon: 0.041247, id: 0.091023] time: 2:26:31.632487 \n","[Epoch 60/1000] [Batch 401/800] [D loss: 0.005038, acc: 100%] [G loss: 3.384477, adv: 1.003592, recon: 0.057167, id: 0.145805] time: 2:27:08.896732 \n","[Epoch 60/1000] [Batch 601/800] [D loss: 0.000577, acc: 100%] [G loss: 3.826938, adv: 0.997780, recon: 0.070981, id: 0.194996] time: 2:27:42.849170 \n","[Epoch 60/1000] [Batch 799/800] [D loss: 0.001062, acc: 100%] [G loss: 3.405798, adv: 0.987883, recon: 0.053764, id: 0.116119] time: 2:28:16.474022 \n","[Epoch 61/1000] [Batch 1/800] [D loss: 0.001109, acc: 100%] [G loss: 3.551225, adv: 0.987919, recon: 0.053418, id: 0.222217] time: 2:28:19.102276 \n","[Epoch 61/1000] [Batch 201/800] [D loss: 0.000628, acc: 100%] [G loss: 3.147276, adv: 0.981622, recon: 0.047777, id: 0.129441] time: 2:28:52.905150 \n","[Epoch 61/1000] [Batch 401/800] [D loss: 0.000233, acc: 100%] [G loss: 3.652044, adv: 0.994437, recon: 0.053684, id: 0.481293] time: 2:29:26.790936 \n","[Epoch 61/1000] [Batch 601/800] [D loss: 0.000565, acc: 100%] [G loss: 3.515553, adv: 1.000184, recon: 0.062012, id: 0.190646] time: 2:30:01.499165 \n","[Epoch 61/1000] [Batch 799/800] [D loss: 0.000988, acc: 100%] [G loss: 3.424801, adv: 0.989570, recon: 0.059942, id: 0.151919] time: 2:30:35.336026 \n","[Epoch 62/1000] [Batch 1/800] [D loss: 0.044586, acc:  98%] [G loss: 4.301444, adv: 1.136317, recon: 0.082946, id: 0.266051] time: 2:30:37.820609 \n","[Epoch 62/1000] [Batch 201/800] [D loss: 0.003114, acc: 100%] [G loss: 3.114664, adv: 0.995481, recon: 0.045479, id: 0.142547] time: 2:31:11.868173 \n","[Epoch 62/1000] [Batch 401/800] [D loss: 0.004738, acc: 100%] [G loss: 3.574390, adv: 0.986230, recon: 0.065337, id: 0.208551] time: 2:31:46.605887 \n","[Epoch 62/1000] [Batch 601/800] [D loss: 0.000598, acc: 100%] [G loss: 3.569945, adv: 0.997505, recon: 0.064882, id: 0.138706] time: 2:32:20.357538 \n","[Epoch 62/1000] [Batch 799/800] [D loss: 0.119754, acc:  75%] [G loss: 3.704200, adv: 0.648845, recon: 0.104326, id: 0.222942] time: 2:32:53.827323 \n","[Epoch 63/1000] [Batch 1/800] [D loss: 0.098551, acc:  85%] [G loss: 3.973835, adv: 0.743728, recon: 0.106884, id: 0.203403] time: 2:32:56.705022 \n","[Epoch 63/1000] [Batch 201/800] [D loss: 0.027330, acc:  99%] [G loss: 3.872285, adv: 1.051472, recon: 0.070692, id: 0.159855] time: 2:33:30.375393 \n","[Epoch 63/1000] [Batch 401/800] [D loss: 0.005041, acc: 100%] [G loss: 3.916065, adv: 1.009776, recon: 0.080903, id: 0.141500] time: 2:34:06.951072 \n","[Epoch 63/1000] [Batch 601/800] [D loss: 0.004438, acc: 100%] [G loss: 4.385587, adv: 1.080234, recon: 0.096167, id: 0.213099] time: 2:34:41.114765 \n","[Epoch 63/1000] [Batch 799/800] [D loss: 0.017134, acc: 100%] [G loss: 4.086364, adv: 0.989451, recon: 0.090079, id: 0.175279] time: 2:35:14.545781 \n","[Epoch 64/1000] [Batch 1/800] [D loss: 0.047811, acc:  96%] [G loss: 4.124915, adv: 0.814583, recon: 0.107475, id: 0.186433] time: 2:35:17.059493 \n","[Epoch 64/1000] [Batch 201/800] [D loss: 0.019279, acc: 100%] [G loss: 3.919568, adv: 0.956102, recon: 0.084658, id: 0.176855] time: 2:35:51.131807 \n","[Epoch 64/1000] [Batch 401/800] [D loss: 0.008212, acc: 100%] [G loss: 3.363575, adv: 0.936174, recon: 0.063674, id: 0.108996] time: 2:36:25.291052 \n","[Epoch 64/1000] [Batch 601/800] [D loss: 0.001464, acc: 100%] [G loss: 3.809919, adv: 1.011143, recon: 0.075174, id: 0.177631] time: 2:36:59.675527 \n","[Epoch 64/1000] [Batch 799/800] [D loss: 0.000986, acc: 100%] [G loss: 4.076954, adv: 1.010013, recon: 0.090244, id: 0.121485] time: 2:37:33.543820 \n","[Epoch 65/1000] [Batch 1/800] [D loss: 0.008618, acc: 100%] [G loss: 3.568921, adv: 0.992463, recon: 0.069452, id: 0.103419] time: 2:37:36.143889 \n","[Epoch 65/1000] [Batch 201/800] [D loss: 0.000466, acc: 100%] [G loss: 3.228547, adv: 1.005316, recon: 0.050779, id: 0.119793] time: 2:38:10.073176 \n","[Epoch 65/1000] [Batch 401/800] [D loss: 0.000433, acc: 100%] [G loss: 3.219816, adv: 0.987604, recon: 0.052935, id: 0.095980] time: 2:38:44.883812 \n","[Epoch 65/1000] [Batch 601/800] [D loss: 0.000891, acc: 100%] [G loss: 3.280749, adv: 0.997971, recon: 0.055317, id: 0.105363] time: 2:39:18.785315 \n","[Epoch 65/1000] [Batch 799/800] [D loss: 0.009535, acc: 100%] [G loss: 3.914732, adv: 0.961305, recon: 0.082630, id: 0.186378] time: 2:39:52.164976 \n","[Epoch 66/1000] [Batch 1/800] [D loss: 0.033036, acc:  96%] [G loss: 3.100375, adv: 0.926478, recon: 0.052473, id: 0.116560] time: 2:39:55.258406 \n","[Epoch 66/1000] [Batch 201/800] [D loss: 0.000631, acc: 100%] [G loss: 3.091078, adv: 0.992342, recon: 0.045886, id: 0.098869] time: 2:40:29.294167 \n","[Epoch 66/1000] [Batch 401/800] [D loss: 0.000336, acc: 100%] [G loss: 3.552288, adv: 1.005207, recon: 0.064633, id: 0.180025] time: 2:41:03.246255 \n","[Epoch 66/1000] [Batch 601/800] [D loss: 0.000287, acc: 100%] [G loss: 3.466846, adv: 0.997796, recon: 0.062135, id: 0.154592] time: 2:41:40.133126 \n","[Epoch 66/1000] [Batch 799/800] [D loss: 0.007189, acc: 100%] [G loss: 3.211259, adv: 1.043351, recon: 0.045258, id: 0.125366] time: 2:42:14.364336 \n","[Epoch 67/1000] [Batch 1/800] [D loss: 0.004783, acc: 100%] [G loss: 3.402350, adv: 0.991460, recon: 0.058929, id: 0.110443] time: 2:42:16.843143 \n","[Epoch 67/1000] [Batch 201/800] [D loss: 0.003131, acc: 100%] [G loss: 4.142522, adv: 1.048670, recon: 0.087914, id: 0.118989] time: 2:42:50.645100 \n","[Epoch 67/1000] [Batch 401/800] [D loss: 0.004707, acc: 100%] [G loss: 3.084500, adv: 0.965595, recon: 0.049751, id: 0.085751] time: 2:43:25.050470 \n","[Epoch 67/1000] [Batch 601/800] [D loss: 0.002981, acc: 100%] [G loss: 3.156644, adv: 1.065794, recon: 0.041913, id: 0.098815] time: 2:43:59.070685 \n","[Epoch 67/1000] [Batch 799/800] [D loss: 0.000275, acc: 100%] [G loss: 3.707598, adv: 0.995915, recon: 0.072413, id: 0.130644] time: 2:44:33.172713 \n","[Epoch 68/1000] [Batch 1/800] [D loss: 0.000797, acc: 100%] [G loss: 3.211621, adv: 1.016213, recon: 0.048347, id: 0.123927] time: 2:44:35.690964 \n","[Epoch 68/1000] [Batch 201/800] [D loss: 0.000282, acc: 100%] [G loss: 3.084213, adv: 0.989759, recon: 0.044730, id: 0.120219] time: 2:45:09.924876 \n","[Epoch 68/1000] [Batch 401/800] [D loss: 0.000409, acc: 100%] [G loss: 3.287633, adv: 0.994988, recon: 0.054927, id: 0.127224] time: 2:45:44.478121 \n","[Epoch 68/1000] [Batch 601/800] [D loss: 0.013271, acc: 100%] [G loss: 3.678960, adv: 1.010844, recon: 0.068291, id: 0.170736] time: 2:46:18.543898 \n","[Epoch 68/1000] [Batch 799/800] [D loss: 0.008044, acc: 100%] [G loss: 3.428230, adv: 1.013214, recon: 0.061694, id: 0.091684] time: 2:46:53.475727 \n","[Epoch 69/1000] [Batch 1/800] [D loss: 0.015583, acc: 100%] [G loss: 3.209989, adv: 0.984772, recon: 0.052875, id: 0.116862] time: 2:46:56.291697 \n","[Epoch 69/1000] [Batch 201/800] [D loss: 0.001003, acc: 100%] [G loss: 3.409572, adv: 1.016945, recon: 0.059570, id: 0.091417] time: 2:47:31.744301 \n","[Epoch 69/1000] [Batch 401/800] [D loss: 0.001477, acc: 100%] [G loss: 3.230469, adv: 0.993480, recon: 0.052478, id: 0.104828] time: 2:48:06.531305 \n","[Epoch 69/1000] [Batch 601/800] [D loss: 0.000451, acc: 100%] [G loss: 3.892869, adv: 0.993741, recon: 0.082816, id: 0.101046] time: 2:48:41.649541 \n","[Epoch 69/1000] [Batch 799/800] [D loss: 0.000254, acc: 100%] [G loss: 3.064490, adv: 0.994480, recon: 0.044754, id: 0.093858] time: 2:49:15.959132 \n","[Epoch 70/1000] [Batch 1/800] [D loss: 0.000446, acc: 100%] [G loss: 3.156915, adv: 0.994697, recon: 0.048388, id: 0.125089] time: 2:49:21.655893 \n","[Epoch 70/1000] [Batch 201/800] [D loss: 0.000930, acc: 100%] [G loss: 3.101907, adv: 1.007227, recon: 0.044493, id: 0.113235] time: 2:49:56.577111 \n","[Epoch 70/1000] [Batch 401/800] [D loss: 0.007178, acc: 100%] [G loss: 3.455496, adv: 0.943857, recon: 0.067011, id: 0.127617] time: 2:50:31.796261 \n","[Epoch 70/1000] [Batch 601/800] [D loss: 0.000943, acc: 100%] [G loss: 3.075420, adv: 0.980915, recon: 0.046544, id: 0.098274] time: 2:51:06.524358 \n","[Epoch 70/1000] [Batch 799/800] [D loss: 0.000922, acc: 100%] [G loss: 3.278615, adv: 1.033053, recon: 0.050049, id: 0.116056] time: 2:51:41.069592 \n","[Epoch 71/1000] [Batch 1/800] [D loss: 0.001024, acc: 100%] [G loss: 3.209306, adv: 1.006046, recon: 0.049210, id: 0.129850] time: 2:51:43.647948 \n","[Epoch 71/1000] [Batch 201/800] [D loss: 0.000928, acc: 100%] [G loss: 3.169643, adv: 1.001159, recon: 0.048032, id: 0.134245] time: 2:52:18.370443 \n","[Epoch 71/1000] [Batch 401/800] [D loss: 0.001157, acc: 100%] [G loss: 3.482455, adv: 1.024130, recon: 0.061442, id: 0.099327] time: 2:52:53.731183 \n","[Epoch 71/1000] [Batch 601/800] [D loss: 0.000574, acc: 100%] [G loss: 3.155925, adv: 0.993602, recon: 0.048146, id: 0.072558] time: 2:53:28.291266 \n","[Epoch 71/1000] [Batch 799/800] [D loss: 0.000663, acc: 100%] [G loss: 3.384202, adv: 0.992035, recon: 0.059736, id: 0.135320] time: 2:54:02.777657 \n","[Epoch 72/1000] [Batch 1/800] [D loss: 0.001111, acc: 100%] [G loss: 3.132130, adv: 0.987588, recon: 0.048563, id: 0.097589] time: 2:54:05.275116 \n","[Epoch 72/1000] [Batch 201/800] [D loss: 0.000428, acc: 100%] [G loss: 3.168457, adv: 1.006359, recon: 0.048408, id: 0.096560] time: 2:54:39.663829 \n","[Epoch 72/1000] [Batch 401/800] [D loss: 0.000523, acc: 100%] [G loss: 2.817962, adv: 0.987366, recon: 0.035471, id: 0.062523] time: 2:55:13.713582 \n","[Epoch 72/1000] [Batch 601/800] [D loss: 0.000969, acc: 100%] [G loss: 2.982218, adv: 0.995049, recon: 0.040807, id: 0.104148] time: 2:55:47.872980 \n","[Epoch 72/1000] [Batch 799/800] [D loss: 0.000976, acc: 100%] [G loss: 3.183478, adv: 0.993281, recon: 0.049800, id: 0.118419] time: 2:56:21.853436 \n","[Epoch 73/1000] [Batch 1/800] [D loss: 0.000684, acc: 100%] [G loss: 3.802051, adv: 1.006271, recon: 0.075641, id: 0.195843] time: 2:56:24.769957 \n","[Epoch 73/1000] [Batch 201/800] [D loss: 0.000361, acc: 100%] [G loss: 3.019732, adv: 0.998466, recon: 0.042897, id: 0.081846] time: 2:56:58.823425 \n","[Epoch 73/1000] [Batch 401/800] [D loss: 0.000865, acc: 100%] [G loss: 3.440281, adv: 0.986853, recon: 0.063720, id: 0.095197] time: 2:57:32.670903 \n","[Epoch 73/1000] [Batch 601/800] [D loss: 0.000547, acc: 100%] [G loss: 3.284490, adv: 1.011090, recon: 0.053701, id: 0.107897] time: 2:58:10.209260 \n","[Epoch 73/1000] [Batch 799/800] [D loss: 0.005300, acc: 100%] [G loss: 3.426245, adv: 1.032123, recon: 0.056237, id: 0.110385] time: 2:58:44.393591 \n","[Epoch 74/1000] [Batch 1/800] [D loss: 0.017182, acc: 100%] [G loss: 2.997178, adv: 0.919598, recon: 0.048501, id: 0.104674] time: 2:58:46.939377 \n","[Epoch 74/1000] [Batch 201/800] [D loss: 0.000332, acc: 100%] [G loss: 3.297945, adv: 1.010239, recon: 0.054850, id: 0.099790] time: 2:59:21.241237 \n","[Epoch 74/1000] [Batch 401/800] [D loss: 0.000255, acc: 100%] [G loss: 2.745238, adv: 0.999294, recon: 0.030878, id: 0.058177] time: 2:59:55.554465 \n","[Epoch 74/1000] [Batch 601/800] [D loss: 0.000617, acc: 100%] [G loss: 3.247278, adv: 1.001695, recon: 0.051266, id: 0.079385] time: 3:00:29.720974 \n","[Epoch 74/1000] [Batch 799/800] [D loss: 0.002041, acc: 100%] [G loss: 3.435758, adv: 1.026474, recon: 0.058618, id: 0.109104] time: 3:01:03.629879 \n","[Epoch 75/1000] [Batch 1/800] [D loss: 0.005227, acc: 100%] [G loss: 2.856177, adv: 0.951272, recon: 0.039489, id: 0.071302] time: 3:01:06.834407 \n","[Epoch 75/1000] [Batch 201/800] [D loss: 0.000300, acc: 100%] [G loss: 3.107230, adv: 1.004502, recon: 0.045534, id: 0.099168] time: 3:01:41.110079 \n","[Epoch 75/1000] [Batch 401/800] [D loss: 0.000231, acc: 100%] [G loss: 3.483540, adv: 0.997415, recon: 0.062804, id: 0.127507] time: 3:02:15.252168 \n","[Epoch 75/1000] [Batch 601/800] [D loss: 0.000335, acc: 100%] [G loss: 3.000699, adv: 0.997243, recon: 0.041683, id: 0.087253] time: 3:02:49.824003 \n","[Epoch 75/1000] [Batch 799/800] [D loss: 0.008215, acc: 100%] [G loss: 2.850371, adv: 0.920916, recon: 0.042648, id: 0.058882] time: 3:03:23.742160 \n","[Epoch 76/1000] [Batch 1/800] [D loss: 0.001970, acc: 100%] [G loss: 2.791862, adv: 0.968650, recon: 0.034610, id: 0.095974] time: 3:03:26.304034 \n","[Epoch 76/1000] [Batch 201/800] [D loss: 0.001081, acc: 100%] [G loss: 3.212989, adv: 1.012030, recon: 0.050625, id: 0.076421] time: 3:04:00.401482 \n","[Epoch 76/1000] [Batch 401/800] [D loss: 0.001071, acc: 100%] [G loss: 2.836846, adv: 0.997158, recon: 0.034043, id: 0.104531] time: 3:04:34.794669 \n","[Epoch 76/1000] [Batch 601/800] [D loss: 0.000354, acc: 100%] [G loss: 3.329591, adv: 0.997566, recon: 0.056256, id: 0.118045] time: 3:05:08.530993 \n","[Epoch 76/1000] [Batch 799/800] [D loss: 0.000585, acc: 100%] [G loss: 2.999628, adv: 0.988862, recon: 0.042800, id: 0.105775] time: 3:05:42.249354 \n","[Epoch 77/1000] [Batch 1/800] [D loss: 0.000351, acc: 100%] [G loss: 3.084708, adv: 1.008169, recon: 0.044025, id: 0.121736] time: 3:05:44.880009 \n","[Epoch 77/1000] [Batch 201/800] [D loss: 0.000844, acc: 100%] [G loss: 3.353826, adv: 1.008621, recon: 0.057834, id: 0.080843] time: 3:06:21.844634 \n","[Epoch 77/1000] [Batch 401/800] [D loss: 0.000319, acc: 100%] [G loss: 3.171824, adv: 0.996810, recon: 0.051220, id: 0.085772] time: 3:06:55.711200 \n","[Epoch 77/1000] [Batch 601/800] [D loss: 0.000219, acc: 100%] [G loss: 3.769474, adv: 1.007194, recon: 0.075302, id: 0.095279] time: 3:07:29.494402 \n","[Epoch 77/1000] [Batch 799/800] [D loss: 0.000291, acc: 100%] [G loss: 3.057565, adv: 1.014432, recon: 0.043484, id: 0.083399] time: 3:08:03.824352 \n","[Epoch 78/1000] [Batch 1/800] [D loss: 0.000633, acc: 100%] [G loss: 3.223995, adv: 0.983933, recon: 0.053194, id: 0.082111] time: 3:08:07.028175 \n","[Epoch 78/1000] [Batch 201/800] [D loss: 0.000205, acc: 100%] [G loss: 2.964886, adv: 0.996978, recon: 0.040878, id: 0.101203] time: 3:08:41.885702 \n","[Epoch 78/1000] [Batch 401/800] [D loss: 0.002045, acc: 100%] [G loss: 3.354632, adv: 0.997051, recon: 0.058028, id: 0.066127] time: 3:09:16.336072 \n","[Epoch 78/1000] [Batch 601/800] [D loss: 0.000327, acc: 100%] [G loss: 3.039803, adv: 1.002433, recon: 0.042927, id: 0.072056] time: 3:09:50.973140 \n","[Epoch 78/1000] [Batch 799/800] [D loss: 0.000671, acc: 100%] [G loss: 3.332310, adv: 1.004401, recon: 0.054884, id: 0.093910] time: 3:10:25.520660 \n","[Epoch 79/1000] [Batch 1/800] [D loss: 0.000202, acc: 100%] [G loss: 2.971150, adv: 1.000498, recon: 0.040339, id: 0.120354] time: 3:10:28.235438 \n","[Epoch 79/1000] [Batch 201/800] [D loss: 0.000202, acc: 100%] [G loss: 3.248919, adv: 0.995816, recon: 0.051990, id: 0.083587] time: 3:11:02.992626 \n","[Epoch 79/1000] [Batch 401/800] [D loss: 0.000202, acc: 100%] [G loss: 2.714739, adv: 0.995844, recon: 0.030047, id: 0.066734] time: 3:11:37.696159 \n","[Epoch 79/1000] [Batch 601/800] [D loss: 0.001338, acc: 100%] [G loss: 3.617123, adv: 1.034201, recon: 0.067741, id: 0.104239] time: 3:12:11.418081 \n","[Epoch 79/1000] [Batch 799/800] [D loss: 0.000407, acc: 100%] [G loss: 2.948409, adv: 1.011027, recon: 0.039497, id: 0.095594] time: 3:12:45.610903 \n","[Epoch 80/1000] [Batch 1/800] [D loss: 0.000496, acc: 100%] [G loss: 3.014362, adv: 1.007850, recon: 0.041944, id: 0.083809] time: 3:12:48.628555 \n","[Epoch 80/1000] [Batch 201/800] [D loss: 0.002102, acc: 100%] [G loss: 2.892433, adv: 0.986931, recon: 0.038000, id: 0.084744] time: 3:13:23.067968 \n","[Epoch 80/1000] [Batch 401/800] [D loss: 0.000350, acc: 100%] [G loss: 2.830349, adv: 0.997686, recon: 0.034123, id: 0.093222] time: 3:13:57.017778 \n","[Epoch 80/1000] [Batch 601/800] [D loss: 0.000233, acc: 100%] [G loss: 3.071685, adv: 0.992903, recon: 0.046448, id: 0.080565] time: 3:14:31.114581 \n","[Epoch 80/1000] [Batch 799/800] [D loss: 0.000115, acc: 100%] [G loss: 2.972466, adv: 0.995588, recon: 0.040981, id: 0.092939] time: 3:15:05.407416 \n","[Epoch 81/1000] [Batch 1/800] [D loss: 0.000121, acc: 100%] [G loss: 3.120758, adv: 1.003206, recon: 0.047153, id: 0.120540] time: 3:15:08.129383 \n","[Epoch 81/1000] [Batch 201/800] [D loss: 0.000171, acc: 100%] [G loss: 2.862384, adv: 1.004922, recon: 0.035168, id: 0.080924] time: 3:15:46.487855 \n","[Epoch 81/1000] [Batch 401/800] [D loss: 0.001887, acc: 100%] [G loss: 3.096868, adv: 0.986107, recon: 0.045570, id: 0.156628] time: 3:16:20.898371 \n","[Epoch 81/1000] [Batch 601/800] [D loss: 0.000998, acc: 100%] [G loss: 2.812266, adv: 0.984225, recon: 0.035006, id: 0.078887] time: 3:16:55.241638 \n","[Epoch 81/1000] [Batch 799/800] [D loss: 0.000287, acc: 100%] [G loss: 3.433367, adv: 1.001367, recon: 0.060040, id: 0.172389] time: 3:17:29.437731 \n","[Epoch 82/1000] [Batch 1/800] [D loss: 0.000250, acc: 100%] [G loss: 3.354059, adv: 1.002731, recon: 0.058180, id: 0.080368] time: 3:17:31.664599 \n","[Epoch 82/1000] [Batch 201/800] [D loss: 0.018084, acc: 100%] [G loss: 3.629152, adv: 0.977057, recon: 0.071891, id: 0.111311] time: 3:18:06.118402 \n","[Epoch 82/1000] [Batch 401/800] [D loss: 0.001259, acc: 100%] [G loss: 2.936176, adv: 1.003561, recon: 0.040964, id: 0.056039] time: 3:18:40.520048 \n","[Epoch 82/1000] [Batch 601/800] [D loss: 0.000513, acc: 100%] [G loss: 3.197906, adv: 1.003401, recon: 0.050365, id: 0.090023] time: 3:19:14.412232 \n"],"name":"stdout"}]}]}